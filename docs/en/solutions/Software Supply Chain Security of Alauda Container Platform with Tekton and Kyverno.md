---
id: KB250600001
products: 
   - Alauda Container Platform
kind:
   - Solution
---
# Software Supply Chain Security of Alauda Container Platform with Tekton and Kyverno

## Overview

In today's software development environment that heavily relies on open source and third-party components, supply chain attacks are becoming increasingly frequent. From the SolarWinds incident to the Log4j vulnerability, these security events have highlighted the critical importance of software supply chain security.

A software supply chain encompasses all entities and processes involved in the software development lifecycle, from application development to CI/CD pipelines and deployment. Modern software is typically composed of multiple components, including open-source software, which may contain vulnerabilities and are often outside developers' direct control. This makes supply chain security a critical responsibility for every organization.

### Understanding major risks in software supply chain

- **Code Integrity Risk**: Risks associated with unauthorized modifications to source code, build processes, or development environments that could compromise software integrity.
- **Dependency Component Risk**: Risks arising from vulnerabilities, malicious code, or compliance issues in third-party dependencies and their supply chain.
- **Build Process Risk**: Risks related to the security and integrity of the build environment, tools, and processes that could lead to compromised artifacts.
- **Distribution Process Risk**: Risks associated with the security of software distribution channels, including container registries, image signing, and transmission security.
- **Deployment and Runtime Risk**: Risks related to the security of deployment environments, configuration management, and runtime dependencies.
- **Compliance Risk**: Risks associated with legal and regulatory requirements, including open source licensing, data privacy, and industry standards.

### Understanding software supply chain security

#### Supply chain security framework

##### Supply chains levels for software artifacts (SLSA)

The Supply chain Levels for Software Artifacts (SLSA) framework is a check-list of controls to prevent tampering, improve integrity, and increase security in the packages and infrastructure used by projects, businesses or enterprises. SLSA formalizes criteria around software supply chain integrity to help the industry and open source ecosystem secure the software development life cycle at all stages.

As part of the framework, SLSA has multiple levels of assurances. These levels contain industry-recognized best practices to create four levels of increasing assurance.

> [Security levels](https://slsa.dev/spec/v1.1/levels)

| Track/Level | Requirements | Focus |
| ----------- | ------------ | ----- |
| Build L0    | (none)       | (n/a) |
| Build L1    | Provenance showing how the package was built | Mistakes, documentation |
| Build L2    | Signed provenance, generated by a hosted build platform | Tampering after the build |
| Build L3    | Hardened build platform | Tampering during the build |

> Tekton can achieve SLSA Level 2 compliance. For more information, please refer to [Getting To SLSA Level 2 with Tekton and Tekton Chains](https://tekton.dev/blog/2023/04/19/getting-to-slsa-level-2-with-tekton-and-tekton-chains/)

#### Security verification mechanisms

##### Image signing

Image signing is used to verify image integrity and prevent tampering during transmission and storage. It is a fundamental verification mechanism that requires only the use of cosign to verify the signature.

##### Keyless signing

Keyless signing is a modern signing method that does not rely on traditional private and public key pairs. Instead, it uses:
- Transparency logs for audit trail

Keyless signing offers several advantages:
- No need to manage private keys
- No key rotation required
- Simplified key management

##### Image attestation

Image attestation is used for storing and verifying metadata information related to images. It provides richer supply chain security information, such as:

- [SLSA Provenance](#slsa-provenance-integrity-attestation)
- [SBOM](#sbom-software-bill-of-materials)
- [Vulnerability scan results](#vulnerability-scan-results)
- [Custom metadata](#custom-metadata)

##### Attestation verification

The verification mechanism is highly flexible and can be customized to validate any metadata present in the attestation. This means that any information stored in the attestation can be used as validation criteria, allowing organizations to implement precise security controls based on their specific requirements.

The flexibility of attestation verification is demonstrated through various validation methods:

- Kyverno [JMESPath](https://jmespath.org/) Validation
   - Uses JMESPath syntax for JSON query and validation

- [Rego](https://www.openpolicyagent.org/docs/latest/policy-language/) Policy Validation
   - Leverages Open Policy Agent (OPA) for complex policy enforcement
   - Supports declarative policy rules and custom validation logic
   - Example: Validating builder information and build environment

- [CUE](https://cuelang.org/) Validation
   - Provides type system and constraint system for validation
   - Enables schema validation and data consistency checks
   - Supports complex data structure validation

#### Attestation types

Attestation types are standardized formats for recording and verifying various aspects of container images. These attestations are typically attached to images using tools like cosign and can be verified through policy engines like Kyverno.

##### SLSA provenance (Integrity attestation)

[SLSA Provenance](https://slsa.dev/provenance/v1) is a set of incrementally adoptable guidelines for supply chain security, established by industry consensus. It includes:
- Build process information
- Build environment details
- Build time information
- Source code information
- Dependencies information

predicate types:
- https://slsa.dev/provenance/v1
- https://slsa.dev/provenance/v0.2

##### SBOM (Software bill of materials)

[SBOM](https://www.ntia.gov/page/software-bill-materials) is a nested inventory for software, a list of ingredients that make up software components, including:
- Software components
- Component versions
- License information
- Dependency relationships

SBOM can be in various formats, such as:
- [SPDX](https://spdx.dev/use/specifications/)
- [CycloneDX](https://cyclonedx.org/specification/overview/)

predicate types:
- https://spdx.dev/Document
- https://cyclonedx.org/bom

##### Vulnerability scan results

[Cosign Vulnerability Scan results](https://github.com/sigstore/cosign/blob/main/specs/COSIGN_VULN_ATTESTATION_SPEC.md) record the security assessment of the software build process, including:
- Scanner information (name, version)
  - Vulnerability database information
- List of discovered vulnerabilities and their severity
- Remediation recommendations

predicate types:
- https://cosign.sigstore.dev/attestation/vuln/v1

##### Custom metadata

Custom metadata can be added as needed to support specific security requirements.

For example, grype can generate vulnerability scan results, and these results can be uploaded to the image registry as a custom type.

predicate types:
- https://cosign.sigstore.dev/attestation/v1

## Understanding implementation methods

Alauda Container Platform leverages the OpenSSF SLSA framework to deliver comprehensive supply chain security. The platform integrates multiple security capabilities through a combination of core components and specialized tools:

Core Components:
- Tekton Pipelines: For pipeline orchestration and automation
- Tekton Chains: For SLSA compliance and artifact signing
- Kyverno: For policy enforcement and validation

Dependency Tools:
- cosign: For image signing and verification
- syft/trivy: For SBOM generation and vulnerability scanning
- grype: For vulnerability scanning

The implementation process is structured into three main phases:

### Phase 1: Attestation generation

| Feature | Standardized Predicate Type | Tool | Description |
|----------------------------|---------------|------|-------------|
| Image Signing | [-](https://github.com/sigstore/cosign/blob/main/specs/SIGNATURE_SPEC.md) | Tekton Chains | Automatically sign images |
| | | cosign | Manually sign images |
| SLSA Provenance | - [https://slsa.dev/provenance/v0.2](https://slsa.dev/provenance/v1)<br>- [https://slsa.dev/provenance/v1](https://slsa.dev/provenance/v1) | Tekton Chains | Generate SLSA Provenance for images<br>Upload TaskRun or PipelineRun metadata to image's SLSA Provenance |
| SBOM | - [https://spdx.dev/Document](https://cyclonedx.org/specification/overview/)<br>- [https://cyclonedx.org/bom](https://cyclonedx.org/specification/overview/) | syft | Generate SBOM files and attach to images |
| | | trivy + cosign | Generate SBOM files using trivy and attach to images via cosign |
| Vulnerability Scan Results | [https://cosign.sigstore.dev/attestation/vuln/v1](https://github.com/sigstore/cosign/blob/main/specs/COSIGN_VULN_ATTESTATION_SPEC.md) | grype + cosign | Generate vulnerability scan results using grype<br>Attach results to images using cosign |
| | | trivy + cosign | Generate vulnerability scan results using trivy<br>Attach results to images using cosign |
| Custom Metadata | [https://cosign.sigstore.dev/attestation/v1](https://github.com/sigstore/cosign/blob/main/specs/COSIGN_PREDICATE_SPEC.md) | cosign | Attach custom metadata to images |

### Phase 2: Attestation validation

| Validation Type | Validation Requirements | Description |
|-----------------|------------------------|-------------|
| Image Signing | Signature Verification | Require image to be signed by specific signers |
| SLSA Provenance | Build Environment | Require image build source to be from specific build environments |
| | Source Code | Require image build source from specific repository address |
| SBOM | Component Requirements | Require SBOM to include or exclude specific software components or versions |
| | Base Image | Require base image to be of specific name and version (operating-system) |
| Vulnerability Scan | Critical Vulnerabilities | Require absence of critical vulnerabilities in scan results |
| | Scan Timing | Require vulnerability scan to be completed within a specific time window |
| Custom Metadata | Custom Requirements | Require custom metadata to include or exclude specific metadata |

### Phase 3: Capability integration

The attestation system provides a flexible and composable framework for software supply chain security.
You can combine different attestations to meet specific security requirements.

Common use cases and their required capabilities:

| Chapter | Description | Required Capabilities | Key Tools |
|---------|-------------|----------------------|-----------|
| 1 | Image signature and verification | Image Signing, Verification | Chains, cosign/Kyverno |
| 2 | Build system verification | SLSA Provenance, Attestation Verification | Chains, Kyverno |
| 3 | Source code repository verification | SLSA Provenance, Attestation Verification | Git Repository, Chains, Kyverno |
| 4 | Vulnerability scan verification | Vulnerability Scan Results, Attestation Verification | grype/trivy, cosign, Kyverno |
| 5 | Base image verification | SBOM, Attestation Verification | syft/trivy, cosign, Kyverno |
| 6 | License compliance verification | SBOM, Attestation Verification | syft/trivy, cosign, Kyverno |
| 7 | (Optional) Keyless signing verification | OIDC Authentication, Keyless Signing | Rekor, cosign, Kyverno |

You can customize these attestations based on your specific requirements.
The system integrates these capabilities to provide comprehensive supply chain security protection.

#### Method 1: Image signature and verification

This method uses Tekton Chains to automatically sign the built image and then use cosign or Kyverno to verify the signature:

1. Configure Tekton Chains to automatically sign the built image.
2. Use `buildah` Tekton Task to build the image.
3. (Optional) Use `cosign` cli to verify the signature.
4. Configure Kyverno rules to allow only signed images.
5. Use the image to create a Pod to verify the signature.

#### Method 2: Build system verification

This method uses Chains to automatically generate SLSA Provenance for the built image and then use Kyverno to verify the provenance:

1. Configure Tekton Chains to automatically generate SLSA Provenance for the built image.
2. Use `buildah` Tekton Task to build the image.
3. (Optional) Use `cosign` cli to verify the attestation.
4. Configure Kyverno rules to verify the attestation.
5. Use the image to create a Pod to verify the attestation.

#### Method 3: Source code repository verification

This method uses Chains to automatically generate SLSA Provenance for the built image and then use Kyverno to verify the provenance:

1. Configure Tekton Chains to automatically generate SLSA Provenance for the built image.
2. Use `git` Tekton Task to get the source code repository.
3. Use `buildah` Tekton Task to build the image.
4. Declare the `git` and `buildah` results information in the results of the Pipeline. This facilitates recording the source code repository and commit information for the image.
5. Configure Kyverno rules to verify the source code repository.
6. Use the image to create a Pod to verify the source code repository.

#### Method 4: Vulnerability scan verification

This method uses tools similar to trivy to scan the image for vulnerabilities and then use Kyverno to verify the vulnerability scan results:

1. Use `trivy` Tekton Task to scan the image for vulnerabilities.
2. Use `cosign` Tekton Task to upload the vulnerability scan results to the image.
3. Configure Kyverno rules to verify the vulnerability scan results.
4. Use the image to create a Pod to verify the vulnerability scan results.

#### Method 5: Base image verification

This method uses tools similar to syft to generate SBOM for the image and then use Kyverno to verify the SBOM:

1. Use `syft` Tekton Task to generate SBOM for the image and attach to the image.
2. Configure Kyverno rules to verify the SBOM.
3. Use the image to create a Pod to verify the SBOM.

#### Method 6: License compliance verification

This method is similar to Method 5, only change the kyverno rules to verify the license compliance.

1. Configure Kyverno rules to verify the SBOM.
2. Use the image to create a Pod to verify the SBOM.

#### Method 7: (Optional) Keyless signing verification

> **Note:**
> - **This method requires the environment to access the Internet.**<br>
> - If you have deployed private [Rekor](https://github.com/sigstore/rekor) services, you can also use these capabilities by adjusting the related configurations.<br>
> - About deploying private [Rekor](https://github.com/sigstore/rekor) services is not in the scope of this document, please refer to the relevant documentation.

This method uses transparency logs to enhance security by eliminating the need for key management:

1. Configure Tekton Chains to use keyless signing.
2. Use `buildah` Tekton Task to build the image.
3. Configure Kyverno rules to verify the keyless signature.
4. Use the image to create a Pod to verify the keyless signature.

## Common Basic Configuration

### Environment Preparation

#### System Requirements

- Alauda Container Platform installed with a working Kubernetes cluster available
- Kubectl command-line tool installed with kubectl-acp plugin for authentication with ACP Platform
- Authenticated to the cluster using kubectl acp login command.
- (Optional) cosign cli installed on your local machine

#### Required Components

- Tekton Chains
- Tekton Pipeline
- Kyverno
- OCI Registry for storing images and signatures

#### Permission Requirements

- Platform administrator privileges for configuring Tekton Chains
- Cluster administrator privileges for configuring Kyverno policies
- Project-level permissions for creating namespaces
- Registry access permissions for pushing and pulling images

### Common Configuration

#### Tekton Chains

> This process requires platform administrator privileges to configure.

##### Generate signing key

> **Note:** This key is used to generate the signature information of the artifact. Please keep it safe.

You can use [cosign](https://github.com/sigstore/cosign) tool to generate signing key.

```sh
$ COSIGN_PASSWORD={password} cosign generate-key-pair k8s://tekton-pipelines/signing-secrets
```

**Note:**

- You need to have cosign CLI installed and access to the k8s cluster.
- `COSIGN_PASSWORD` is the password for encrypting the signing key.
- `tekton-pipelines` is the namespace where the Chains component is deployed, default is `tekton-pipelines`.
- `signing-secrets` is the name of the Secret for storing the signing key.

After the execution, you can view the corresponding Secret resource.

```sh
$ kubectl get secret signing-secrets -n tekton-pipelines -o yaml

apiVersion: v1
data:
  cosign.key: <base64-encoded-private-key>
  cosign.password: <base64-encoded-password>
  cosign.pub: <base64-encoded-public-key>
immutable: true
kind: Secret
metadata:
  name: signing-secrets
  namespace: tekton-pipelines
type: Opaque
```

##### Get the signing public key

> If you don't have permission, you can ask the administrator to get the public key.

```sh
$ export NAMESPACE=<tekton-pipelines>
$ kubectl get secret -n $NAMESPACE signing-secrets -o jsonpath='{.data.cosign\.pub}' | base64 -d > cosign.pub
```

##### Get the signing secret

```sh
$ export NAMESPACE=<tekton-pipelines>
$ kubectl get secret -n $NAMESPACE signing-secrets -o yaml > signing-secrets.yaml
```

##### Restart Tekton Chains component to make the signing key take effect

```sh
$ kubectl delete pods -n tekton-pipelines -l app=tekton-chains-controller
```

Wait for the component to start.

```sh
$ kubectl get pods -n tekton-pipelines -l app=tekton-chains-controller -w

NAME                                        READY   STATUS    RESTARTS   AGE
tekton-chains-controller-55876dfbbd-5wv5z   1/1     Running   0          1m30s
```

##### Tekton Chains Configuration

Configure Tekton Chains to automatically generate signatures and SLSA Provenance for OCI artifacts.

```shell
$ kubectl patch tektonconfigs.operator.tekton.dev config --type=merge -p='{
  "spec": {
    "chain": {
      "artifacts.oci.format": "simplesigning",
      "artifacts.oci.storage": "oci",
      "artifacts.pipelinerun.format": "in-toto",
      "artifacts.pipelinerun.storage": "oci",
      "artifacts.taskrun.format": "in-toto",
      "artifacts.taskrun.storage": "oci",
      "builder.id": "https://alauda.io/builders/tekton/v1"
    }
  }
}'
```

> If your registry uses a self-signed certificate, you need to add the following configuration to the `config` of `TektonConfig`.
>
> ```shell
> $ kubectl patch tektonconfigs.operator.tekton.dev config --type=merge -p='{
>   "spec": {
>     "chain": {
>       "storage.oci.repository.insecure": true
>     }
>   }
> }'
> ```

> More details about Tekton Chains Configuration, please refer to [Tekton Chains Configuration](https://github.com/tektoncd/chains/blob/main/docs/config.md)

> By default, Tekton Chains is deployed automatically through the `TektonConfig` resource. You can modify the `TektonConfig` resource to configure Chains.<br>
> Essentially, Tekton Operator will synchronize the Chains configuration from the `TektonConfig` resource to the `TektonChains` resource, and finally reflect in the `chains-config` ConfigMap.<br>
> You can view the configuration by `kubectl get configmaps -n <tekton-pipelines> chains-config -o yaml`

#### Registry Configuration

> This process needs to be done in the namespace where the image will be built and deployed.

##### Create registry secret

```shell
$ export NAMESPACE=<default>
$ export REGISTRY_CREDENTIALS=<registry-credentials>

$ kubectl create secret docker-registry -n $NAMESPACE $REGISTRY_CREDENTIALS \
  --docker-server=<registry-server> \
  --docker-username=<username> \
  --docker-email=<someemail@something.com> \
  --docker-password=<password>
```

##### Set the `config.json` key

```shell
$ DOCKER_CONFIG=$(kubectl get secret -n $NAMESPACE $REGISTRY_CREDENTIALS -o jsonpath='{.data.\.dockerconfigjson}')
$ kubectl patch secret -n $NAMESPACE $REGISTRY_CREDENTIALS -p "{\"data\":{\"config.json\":\"$DOCKER_CONFIG\"}}"
```

##### Get the registry secret

```shell
$ kubectl get secret -n $NAMESPACE $REGISTRY_CREDENTIALS -o yaml

apiVersion: v1
data:
  .dockerconfigjson: <base64-encoded-dockerconfigjson>
  config.json: <base64-encoded-config.json>
kind: Secret
metadata:
  name: <registry-credentials>
type: kubernetes.io/dockerconfigjson
```

#### ServiceAccount Configuration

> This process needs to be done in the namespace where the image will be built and deployed.

Add registry credentials to ServiceAccount for image build and signature push.

```shell
$ export NAMESPACE=<default>
$ export SERVICE_ACCOUNT_NAME=<default>
$ export REGISTRY_CREDENTIALS=<registry-credentials>

$ kubectl patch serviceaccount -n $NAMESPACE $SERVICE_ACCOUNT_NAME \
  -p "{\"imagePullSecrets\": [{\"name\": \"$REGISTRY_CREDENTIALS\"}]}"
```

#### Kyverno Configuration

> This process requires cluster administrator privileges to configure.

Since Kyverno needs registry credentials to verify image signatures, you need to create a registry secret in the namespace where Kyverno is deployed.

In our environment, the namespace is usually `kyverno`.

### Basic Concepts

#### Image Signing
- Digital signature for an image to ensure its integrity and authenticity
- Uses cosign for signing and verification
- Supports both traditional key-based and keyless signing methods

#### Image Attestation
- Metadata information related to images
- Includes SLSA Provenance, SBOM, vulnerability scan results
- Stored alongside the image in the registry

#### SLSA Provenance
- Records the integrity attestation of the software build process
- Includes build process information, environment details, source code information
- Helps verify the build process and source of the image

#### Kyverno Policy
- Policy engine for Kubernetes
- Used for validating images and enforcing security policies
- Supports complex validation rules using JMESPath expressions

#### Tekton Chains Type Hinting

> More details about type hinting can be found in the [Tekton Chains Type Hinting](https://tekton.dev/docs/chains/slsa-provenance/#type-hinting) documentation.

Type Hinting is a special mechanism in Tekton Chains that helps Chains understand input artifacts and output artifacts in PipelineRun/TaskRun through specific naming conventions.

**Purpose**
- Helps Chains correctly identify and record input and output artifacts in the build process
- Generates accurate SLSA Provenance attestations
- Ensures traceability and integrity of the build process

There are several ways to specify input and output artifacts:

##### **CHAINS-GIT_URL and CHAINS-GIT_COMMIT combination**
- Special type hints for Git repository information
- Used to track source code repository details
- Helps in provenance generation for source code
```yaml
results:
  - name: CHAINS-GIT_URL
    type: string
  - name: CHAINS-GIT_COMMIT
    type: string
```

##### **\*ARTIFACT_INPUTS**

> **Note:**
> - `*` indicates any expression

- Used to specify input artifacts that influenced the build process
- Helps track dependencies and source materials
```yaml
results:
  - name: first-ARTIFACT_INPUTS
    type: object
    properties:
      uri: {}
      digest: {}
```

##### **\*IMAGE_URL and \*IMAGE_DIGEST combination**
```yaml
results:
  - name: first-image-IMAGE_URL
    type: string
  - name: first-image-IMAGE_DIGEST
    type: string
```

##### **IMAGES**
- Can specify multiple images, separated by commas or newlines
- Each image must include the complete digest
```yaml
results:
  - name: IMAGES
    type: string
```

##### **\*ARTIFACT_URI / \*ARTIFACT_DIGEST combination**
- Similar to IMAGE_URL/IMAGE_DIGEST but with different naming convention
- Used for specifying artifact location and its digest
```yaml
results:
  - name: first-ARTIFACT_URI
    type: string
  - name: first-ARTIFACT_DIGEST
    type: string
```

##### **\*ARTIFACT_OUTPUTS**
- Uses object type results
- Must include uri and digest fields
```yaml
results:
  - name: first-ARTIFACT_OUTPUTS
    type: object
    properties:
      uri: {}
      digest: {}
```

## Chapter 1. Enforcing Image Signature: Automated Signing and Deployment Control

In ACP (Alauda Container Platform), you can use Tekton Chains to automatically sign the Tekton Pipeline built image, and use Kyverno to allow only signed images to be deployed.

This chapter explains how to implement the above process step by step.

### Step 1: Prerequisites

Please check if the prerequisites are completed, especially about this section:

- [Registry Configuration](#registry-configuration)
- [ServiceAccount Configuration](#serviceaccount-configuration)
- [Get the signing public key](#get-the-signing-public-key)

### Step 2: Create a pipeline to generate the image

This is a Pipeline resource, which is used to generate the image.

```yaml
apiVersion: tekton.dev/v1
kind: Pipeline
metadata:
  name: chains-demo-1
spec:
  params:
    - default: |-
        echo "Generate a Dockerfile for building an image."

        cat << 'EOF' > Dockerfile
        FROM ubuntu:latest
        ENV TIME=1
        EOF

        echo -e "\nDockerfile contents:"
        echo "-------------------"
        cat Dockerfile
        echo "-------------------"
        echo -e "\nDockerfile generated successfully!"
      description: A script to generate a Dockerfile for building an image.
      name: generate-dockerfile
      type: string
    - default: <registry>/test/chains/demo-1:latest
      description: The target image address built
      name: image
      type: string
  tasks:
    - name: generate-dockerfile
      params:
        - name: script
          value: $(params.generate-dockerfile)
      taskRef:
        params:
          - name: kind
            value: task
          - name: catalog
            value: catalog
          - name: name
            value: run-script
          - name: version
            value: "0.1"
        resolver: hub
      timeout: 30m0s
      workspaces:
        - name: source
          workspace: source
    - name: build-image
      params:
        - name: IMAGES
          value:
            - $(params.image)
        - name: TLS_VERIFY
          value: "false"
      runAfter:
        - generate-dockerfile
      taskRef:
        params:
          - name: kind
            value: task
          - name: catalog
            value: catalog
          - name: name
            value: buildah
          - name: version
            value: "0.9"
        resolver: hub
      timeout: 30m0s
      workspaces:
        - name: source
          workspace: source
        - name: dockerconfig
          workspace: dockerconfig
  results:
    - description: first image artifact output
      name: first_image_ARTIFACT_OUTPUTS
      type: object
      value:
        digest: $(tasks.build-image.results.IMAGE_DIGEST)
        uri: $(tasks.build-image.results.IMAGE_URL)
  workspaces:
    - name: source
      description: The workspace for source code.
    - name: dockerconfig
      description: The workspace for Docker configuration.
```

> **Note:**
>
> This tutorial demonstrates a simplified workflow by generating the `Dockerfile` inline within the pipeline.
> In production environments, you would typically:
>
> 1. Use the `git-clone` task to fetch source code from your repository
> 2. Build the image using the Dockerfile that exists in your source code
> 3. This approach ensures proper version control and maintains the separation between code and pipeline configuration

**Explanation of YAML fields:**

- `params`: The parameters for the pipeline.
  - `generate-dockerfile`: The script to generate a Dockerfile for building an image.
  - `image`: The target image address built.
- `tasks`: The tasks for the pipeline.
  - `generate-dockerfile`: The task to generate a Dockerfile for building an image.
  - `build-image`: The task to build and push the image to the registry.
    - `params.TLS_VERIFY`: Whether to verify the TLS certificate of the registry.
- `results`: The results for the pipeline.
  - `first_image_ARTIFACT_OUTPUTS`: The result of the first image artifact output.
    - `digest`: The digest of the image.
    - `uri`: The URI of the image.
  - This format is compliant with Tekton Chains, see [Tekton Chains Type Hinting](#tekton-chains-type-hinting) in above section for more details.
- `workspaces`: The workspaces for the pipeline.
  - `source`: The workspace for source code.
  - `dockerconfig`: The workspace for Docker configuration.

**Need to adjust the configuration**
- `params`:
  - `generate-dockerfile`
    - `default`: Adjust the from image address.
  - `image`:
    - `default`: The target image address built.

Save into a yaml file named `chains.demo-1.pipeline.yaml` and apply it with:

```shell
$ export NAMESPACE=<default>

# create the pipeline resource in the namespace
$ kubectl apply -n $NAMESPACE -f chains.demo-1.pipeline.yaml
```

### Step 3: Run the pipeline to generate the image

This is a PipelineRun resource, which is used to run the pipeline.

```yaml
apiVersion: tekton.dev/v1
kind: PipelineRun
metadata:
  generateName: chains-demo-1-
spec:
  pipelineRef:
    name: chains-demo-1
  taskRunTemplate:
    serviceAccountName: <default>
  workspaces:
    - name: dockerconfig
      secret:
        secretName: <registry-credentials>
    - name: source
      volumeClaimTemplate:
        spec:
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 1Gi
          storageClassName: <nfs>
```

**Explanation of YAML fields:**

- `pipelineRef`: The pipeline to run.
  - `name`: The name of the pipeline.
- `taskRunTemplate`: The task run template.
  - `serviceAccountName`: The service account to use for the pipeline.
- `workspaces`: The workspaces for the pipeline.
  - `dockerconfig`: The workspace for Docker configuration.
  - `source`: The workspace for source code.

**Need to adjust the configuration**

- `taskRunTemplate`:
  - `serviceAccountName`: The service account prepared in the previous step [ServiceAccount Configuration](#serviceaccount-configuration).
- `workspaces`:
  - `dockerconfig`:
    - `secret.secretName`: The registry secret prepared in the previous step [Registry Configuration](#registry-configuration).
  - `source`:
    - `volumeClaimTemplate.spec.storageClassName`: The storage class name for the volume claim template.

Save into a yaml file named `chains.demo-1.pipelinerun.yaml` and apply it with:

```shell
$ export NAMESPACE=<default>

# create the pipeline run resource in the namespace
$ kubectl create -n $NAMESPACE -f chains.demo-1.pipelinerun.yaml
```

Wait for the PipelineRun to complete.

```shell
$ kubectl get pipelinerun -n $NAMESPACE -w

chains-demo-1-<xxxxx>   True        Succeeded   2m         2m
```

### Step 4: Wait for the PipelineRun to be signed

Wait for the PipelineRun has `chains.tekton.dev/signed: "true"` annotation.

```shell
$ export NAMESPACE=<default>
$ export PIPELINERUN_NAME=<chains-demo-1-xxxxx>

$ kubectl get pipelinerun -n $NAMESPACE $PIPELINERUN_NAME -o yaml | grep "chains.tekton.dev/signed"

    chains.tekton.dev/signed: "true"
```

Once the PipelineRun has `chains.tekton.dev/signed: "true"` annotation, means the image is signed.

### Step 5: Get the image from the PipelineRun

```shell
# Get the image URI
$ export IMAGE_URI=$(kubectl get pipelinerun -n $NAMESPACE $PIPELINERUN_NAME -o jsonpath='{.status.results[?(@.name=="first_image_ARTIFACT_OUTPUTS")].value.uri}')

# Get the image digest
$ export IMAGE_DIGEST=$(kubectl get pipelinerun -n $NAMESPACE $PIPELINERUN_NAME -o jsonpath='{.status.results[?(@.name=="first_image_ARTIFACT_OUTPUTS")].value.digest}')

# Combine the image URI and digest to form the full image reference
$ export IMAGE=$IMAGE_URI@$IMAGE_DIGEST

# Print the image reference
$ echo $IMAGE

<registry>/test/chains/demo-1:latest@sha256:93635f39cb31de5c6988cdf1f10435c41b3fb85570c930d51d41bbadc1a90046
```

This image will be used to verify the signature.

### Step 6: (Optional) Verify the signature with cosign

> **Tips:**:
>
> - This step is optional and should be performed when you need to verify the signature of the image by cosign.
> - If you interested how to use cosign to verify the signature, you can continue to read the following content.

Get the signing public key according to the [Get the signing public key](#get-the-signing-public-key) section.

Verify the signature with cosign.

```shell
# Disable tlog upload and enable private infrastructure
$ export COSIGN_TLOG_UPLOAD=false
$ export COSIGN_PRIVATE_INFRASTRUCTURE=true

$ cosign verify --key cosign.pub ${IMAGE}
```

Receive the output like this, means the signature verification is successful.

```text
[{"critical":{"identity":{"docker-reference":"<registry>/test/chains/demo-1"},"image":{"docker-manifest-digest":"sha256:93635f39cb31de5c6988cdf1f10435c41b3fb85570c930d51d41bbadc1a90046"},"type":"cosign container image signature"},"optional":null}]
```

You can use `cosign` to verify the unsigned image.

```shell
$ cosign verify --key cosign.pub ${IMAGE}
```

Receive the output like this, means the signature verification is failed.

```text
Error: no signatures found
error during command execution: no signatures found
```

### Step 7: Verify the signature with Kyverno

#### Step 7.1: Create a Kyverno policy to allow only signed images to be deployed

> This step requires cluster administrator privileges.

The policy is as follows:

```yaml
apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: only-cosign-image-deploy
spec:
  webhookConfiguration:
    failurePolicy: Fail
    timeoutSeconds: 30
  background: false
  rules:
    - name: check-image
      match:
        any:
          - resources:
              kinds:
                - Pod
              namespaces:
                - policy
      verifyImages:
        - imageReferences:
            - "*"
            # - "<registry>/test/*"
          skipImageReferences:
            - "ghcr.io/trusted/*"
          failureAction: Enforce
          verifyDigest: false
          required: false
          useCache: false
          imageRegistryCredentials:
            allowInsecureRegistry: true
            secrets:
              # The credential needs to exist in the namespace where kyverno is deployed
              - registry-credentials

          attestors:
            - count: 1
              entries:
                - keys:
                    publicKeys: |- # <- The public key of the signer
                      -----BEGIN PUBLIC KEY-----
                      MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEFZNGfYwn7+b4uSdEYLKjxWi3xtP3
                      UkR8hQvGrG25r0Ikoq0hI3/tr0m7ecvfM75TKh5jGAlLKSZUJpmCGaTToQ==
                      -----END PUBLIC KEY-----

                    ctlog:
                      ignoreSCT: true

                    rekor:
                      ignoreTlog: true
```

> More details about Kyverno ClusterPolicy, please refer to [Kyverno ClusterPolicy](https://kyverno.io/docs/policy-types/cluster-policy/)

**Explanation of YAML fields:**

- `spec.rules[].match.any[].resources`: The resources to be matched and validated.
  - `kinds`: The kinds of the resources to be matched and validated.
    - `Pod`: The Pod resources.
  - `namespaces`: The namespaces of the resources to be matched and validated.
    - `policy`: The resources in the `policy` namespace will be matched and validated.
- `spec.rules[].verifyImages`: The verify images
  - `imageReferences`: The image references to be verified.
    - `*`: all image references will be verified.
    - `<registry>/test/*`: only image references in the `<registry>/test` registry will be verified.
  - `skipImageReferences`: The image references to be skipped.
    - `ghcr.io/trusted/*`: only image references in the `ghcr.io/trusted` registry will be skipped.
  - `imageRegistryCredentials`:
    - `allowInsecureRegistry`: Whether to allow insecure registry.
    - `secrets`: The secrets to be used for the image registry credentials.
      - `registry-credentials`: The name of the secret. The secret needs to exist in the namespace where kyverno is deployed.
  - `attestors`: The attestors to be used for the image verification.
    - `count`: The count of the attestors need to be matched.
    - `entries`: The entries of the attestors.
      - `keys`: The keys of the attestors.
        - `publicKeys`: The public keys of the attestors.
          - This public key is the same as the public key `cosign.pub` in the `signing-secrets` secret.
        - `ctlog`: The ctlog of the attestors.
          - `ignoreSCT`: Whether to ignore the SCT.
            - In isolated network environments, ignore the SCT first.
        - `rekor`: The rekor of the attestors.
          - `ignoreTlog`: Whether to ignore the Tlog.
            - In isolated network environments, ignore the Tlog first.

**Need to adjust the configuration**

- `spec.rules[].attestors[].entries[].keys.publicKeys`: The public key of the signer.
  - This public key is the same as the public key `cosign.pub` in the `signing-secrets` secret.
  - The public key can be obtained from the [Get the signing public key](#get-the-signing-public-key) section.

Save into a yaml file named `kyverno.only-cosign-image-deploy.yaml` and apply it with:

```shell
$ kubectl apply -f kyverno.only-cosign-image-deploy.yaml

clusterpolicy.kyverno.io/only-cosign-image-deploy configured
```

#### Step 7.2: Verify the policy

In the `policy` namespace where the policy is defined, create a Pod to verify the policy.

Use the signed image created by the pipeline to create a Pod.

```shell
$ export NAMESPACE=<policy>
$ export IMAGE=<<registry>/test/chains/demo-1:latest@sha256:93635f39cb31de5c6988cdf1f10435c41b3fb85570c930d51d41bbadc1a90046>

$ kubectl run -n $NAMESPACE signed --image=${IMAGE} -- sleep 3600

pod/signed created
```

The Pod will be created successfully.

```shell
$ export NAMESPACE=<policy>
$ kubectl get pod -n $NAMESPACE signed

NAME      READY   STATUS    RESTARTS   AGE
signed   1/1     Running   0          10s
```

Use the unsigned image to create a Pod.

```shell
$ export NAMESPACE=<policy>
$ export IMAGE=<<registry>/test/chains/unsigned:latest>

$ kubectl run -n $NAMESPACE unsigned --image=${IMAGE} -- sleep 3600
```

Receive the output like this, means the Pod is blocked by the policy.

```text
Error from server: admission webhook "mutate.kyverno.svc-fail" denied the request:

resource Pod/policy/unsigned was blocked due to the following policies

only-cosign-image-deploy:
  check-image: 'failed to verify image ubuntu:latest:
    .attestors[0].entries[0].keys: no signatures found'
```

### Step 8: Clean up the resources

Delete the Pods created in the previous steps.

```shell
$ export NAMESPACE=<policy>
$ kubectl delete pod -n $NAMESPACE signed

pod "signed" deleted
```

Delete the policy.

```shell
$ kubectl delete clusterpolicy only-cosign-image-deploy
```

## Chapter 2. Enforcing Build Environment-based Image Deployment

In ACP (Alauda Container Platform), you can use Tekton Chains to automatically generate the SLSA provenance for image.

In the SLSA provenance, there is a `builder.id` field, which is used to indicate the build environment of the image. In this chapter, we will use this `builder.id` field to verify the image.

> **Tips:**
>
> **Since Tekton Chains has already handled both image signing and SLSA provenance generation in the preparation stage, we can directly reuse the process and images from [Chapter 1](#chapter-1-enforcing-image-signature-automated-signing-and-deployment-control).**<br>
> **We will focus on verifying the SLSA provenance in this chapter.**

This chapter explains how to implement the above process step by step.

### Step 1: Prerequisites

Please check if the prerequisites are completed, especially about this section:

- [Registry Configuration](#registry-configuration)
- [ServiceAccount Configuration](#serviceaccount-configuration)
- [Get the signing public key](#get-the-signing-public-key)

If you want to change the default `builder.id`, you can adjust the `builder.id` field in the `config` of `TektonConfig`.

> This process requires platform administrator privileges to configure.

```shell
$ kubectl patch tektonconfigs.operator.tekton.dev config --type=merge -p='{
  "spec": {
    "chain": {
      "builder.id": "https://alauda.io/builders/tekton/v1"
    }
  }
}'
```

### Step 2: (Optional) Re-run the pipeline to generate the image

> **Tips:**
>
> **If you change the `builder.id` field, you need to re-run the pipeline to generate the image.**<br>
> Because the old image is not signed with the new `builder.id`, so it will be blocked by the policy.<br>
> Otherwise, you can skip this step, use the old image to verify the policy.

To regenerate and obtain the image, follow these steps:

- [Chapter 1: Run the pipeline to generate the image](#step-3-run-the-pipeline-to-generate-the-image)
- [Chapter 1: Wait for the pipeline to be signed](#step-4-wait-for-the-pipeline-to-be-signed)
- [Chapter 1: Get the image from the pipelinerun](#step-5-get-the-image-from-the-pipelinerun)

### Step 3: (Optional) Verify the builder info with cosign

> **Tips:**:
>
> - This step is optional and should be performed when you need to verify the authenticity of the image builder by cosign.
> - If you interested how to use cue or rego to verify the builder info, you can continue to read the following content.

Get the signing public key according to the [Get the signing public key](#get-the-signing-public-key) section.

Cosign provides two ways to [validate the attestation](https://docs.sigstore.dev/cosign/verifying/attestation/):

- [CUE](https://cuelang.org/)
- [Rego](https://www.openpolicyagent.org/docs/latest/policy-language/)

The following will show the verification methods of these two ways.

##### Way 1: Use [CUE](https://cuelang.org/) to verify

Generate the CUE file to verify the builder info.

```cue
// The predicate must match the following constraints.
predicate: {
    builder: {
        id: "https://alauda.io/builders/tekton/v1"
    }
}
```

Save the CUE file to `builder.cue`

Verify the builder info with cosign.

```shell
# Disable tlog upload and enable private infrastructure
$ export COSIGN_TLOG_UPLOAD=false
$ export COSIGN_PRIVATE_INFRASTRUCTURE=true

$ export IMAGE=<<registry>/test/chains/demo-1:latest@sha256:93635f39cb31de5c6988cdf1f10435c41b3fb85570c930d51d41bbadc1a90046>

$ cosign verify-attestation --key cosign.pub --type slsaprovenance --policy builder.cue $IMAGE
```

Receive the output like this, means the builder info verification is successful.

```text
will be validating against CUE policies: [builder.cue]
will be validating against CUE policies: [builder.cue]

Verification for <registry>/test/chains/demo-1:latest@sha256:8ac1af8dd89652bf32abbbd0c5f667ae9fe6d92c91972617e70b5398303c8e27 --
The following checks were performed on each of these signatures:
  - The cosign claims were validated
  - The signatures were verified against the specified public key
{"payloadType":"application/vnd.in-toto+json","payload":"","signatures":[]}
```

Change the builder id in the `builder.cue` file to an other value `https://alauda.io/builders/tekton/v2`, and verify again.

```shell
$ cosign verify-attestation --key cosign.pub --type slsaprovenance --policy builder.cue $IMAGE
```

Receive the output like this, means the builder info verification is failed.

```text
will be validating against CUE policies: [builder.cue]
will be validating against CUE policies: [builder.cue]
There are 2 number of errors occurred during the validation:

- predicate.builder.id: conflicting values "https://alauda.io/builders/tekton/v1" and "https://alauda.io/builders/tekton/v2"
- predicate.builder.id: conflicting values "https://alauda.io/builders/tekton/v1" and "https://alauda.io/builders/tekton/v2"
Error: 2 validation errors occurred
error during command execution: 2 validation errors occurred
```

##### Way 2: Use [Rego](https://www.openpolicyagent.org/docs/latest/policy-language/) to verify

Generate the Rego file to verify the builder info.

```
package signature

default allow = false

# Define the allowed builder.id
allowed_builder_id = "https://alauda.io/builders/tekton/v1"

# Verify the builder.id
allow {
    # Check if the builder.id in the predicate is equal to the allowed value
    input.predicate.builder.id == allowed_builder_id
}

# Return error message when not match
deny[msg] {
    input.predicate.builder.id != allowed_builder_id
    msg := sprintf("unexpected builder.id: %v, expected: %v", [input.predicate.builder.id, allowed_builder_id])
}
```

Save the Rego file to `builder.rego`

Verify the builder info with cosign.

```shell
# Disable tlog upload and enable private infrastructure
$ export COSIGN_TLOG_UPLOAD=false
$ export COSIGN_PRIVATE_INFRASTRUCTURE=true

$ export IMAGE=<<registry>/test/chains/demo-1:latest@sha256:93635f39cb31de5c6988cdf1f10435c41b3fb85570c930d51d41bbadc1a90046>

$ cosign verify-attestation --key cosign.pub --type slsaprovenance --policy builder.rego $IMAGE
```

Receive the output like this, means the builder info verification is successful.

```text
will be validating against Rego policies: [builder.rego]
will be validating against Rego policies: [builder.rego]

Verification for <registry>/test/chains/demo-1:latest --
The following checks were performed on each of these signatures:
  - The cosign claims were validated
  - The signatures were verified against the specified public key
{"payloadType":"application/vnd.in-toto+json","payload":"","signatures":[]}
```

Change the builder id in the `builder.rego` file to an other value `https://alauda.io/builders/tekton/v2`, and verify again.

```shell
$ cosign verify-attestation --key cosign.pub --type slsaprovenance --policy builder.rego $IMAGE
```

Receive the output like this, means the builder info verification is failed.

```text
will be validating against Rego policies: [builder.rego]
will be validating against Rego policies: [builder.rego]
There are 2 number of errors occurred during the validation:

- expression value, false, is not true
- expression value, false, is not true
Error: 2 validation errors occurred
error during command execution: 2 validation errors occurred
```

### Step 4: Verify image builder information with Kyverno

> This step needs cluster administrator permission.

The content of the provenance is roughly as follows, we will use the `builder.id` field to verify the build environment.

```json
{
  "_type": "https://in-toto.io/Statement/v0.1",
  "predicateType": "https://slsa.dev/provenance/v0.2",
  "predicate": {
    "buildType": "tekton.dev/v1beta1/TaskRun",
    "builder": {
      "id": "https://alauda.io/builders/tekton/v1"
    },
    "materials": [
      {
        "digest": {
          "sha256": "8d5ea9ecd9b531e798fecd87ca3b64ee1c95e4f2621d09e893c58ed593bfd4c4"
        },
        "uri": "oci://<registry>/devops/tektoncd/hub/buildah"
      }
    ],
    "metadata": {
      "buildFinishedOn": "2025-06-06T10:21:27Z",
      "buildStartedOn": "2025-06-06T10:20:55Z"
    }
  }
}
```

#### Step 4.1: Create a Kyverno policy to allow only images built in specific build environments to be deployed

> This step requires cluster administrator privileges.

The policy is as follows:

```yaml
apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: verify-tekton-built-images
spec:
  webhookConfiguration:
    failurePolicy: Fail
    timeoutSeconds: 30
  background: false
  rules:
    - name: check-image
      match:
        any:
          - resources:
              kinds:
                - Pod
              namespaces:
                - policy
      verifyImages:
        - imageReferences:
            - "*"
            # - "<registry>/test/*"
          skipImageReferences:
            - "ghcr.io/trusted/*"
          failureAction: Enforce
          verifyDigest: false
          required: false
          useCache: false
          imageRegistryCredentials:
            allowInsecureRegistry: true
            secrets:
              # The credential needs to exist in the namespace where kyverno is deployed
              - registry-credentials

          attestations:
            - type: https://slsa.dev/provenance/v0.2
              attestors:
                - entries:
                    - keys:
                        publicKeys: |- # <- The public key of the signer
                          -----BEGIN PUBLIC KEY-----
                          MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEFZNGfYwn7+b4uSdEYLKjxWi3xtP3
                          UkR8hQvGrG25r0Ikoq0hI3/tr0m7ecvfM75TKh5jGAlLKSZUJpmCGaTToQ==
                          -----END PUBLIC KEY-----

                        ctlog:
                          ignoreSCT: true

                        rekor:
                          ignoreTlog: true
              conditions:
                - all:
                    - key: "{{ builder.id }}"
                      operator: Equals
                      value: "https://alauda.io/builders/tekton/v1"
                      message: "The builder.id must be equal to https://alauda.io/builders/tekton/v1, not {{ builder.id }}"
```

> More details about Kyverno ClusterPolicy, please refer to [Kyverno ClusterPolicy](https://kyverno.io/docs/policy-types/cluster-policy/)

**Explanation of YAML fields:**

- The policy is largely consistent with the one in [Chapter 1: Create a Kyverno policy to allow only signed images to be deployed](#step-71-create-a-kyverno-policy-to-allow-only-signed-images-to-be-deployed). Below only introduces the differences.
- `spec.rules[0].verifyImages[].attestations[0].conditions`
  - `type`: The slsa provenance type is `https://slsa.dev/provenance/v0.2` or `https://slsa.dev/provenance/v1`.
  - `attestors`: the same as above.
  - `conditions`: The conditions to be verified.
    - `all`: All conditions must be met.
      - `key: "{{ builder.id }}"`: This check the `builder.id` field in the attestation is equal to `https://alauda.io/builders/tekton/v1`

Save the policy to a yaml file named `kyverno.verify-tekton-built-images.yaml` and apply it with:

```shell
$ kubectl apply -f kyverno.verify-tekton-built-images.yaml

clusterpolicy.kyverno.io/verify-tekton-built-images configured
```

#### Step 4.2: Verify the policy

In the `policy` namespace where the policy is defined, create a Pod to verify the policy.

Use the built image to create a Pod.

```shell
$ export NAMESPACE=<policy>
$ export IMAGE=<<registry>/test/chains/demo-1:latest@sha256:93635f39cb31de5c6988cdf1f10435c41b3fb85570c930d51d41bbadc1a90046>

$ kubectl run -n $NAMESPACE built --image=${IMAGE} -- sleep 3600

pod/built created
```

The Pod will be created successfully.

```shell
$ kubectl get pod -n $NAMESPACE built

NAME      READY   STATUS    RESTARTS   AGE
built   1/1     Running   0          10s
```

Change the builder id in the `ClusterPolicy` to an other value `https://alauda.io/builders/tekton/v2`, and verify again.

```yaml
conditions:
  - all:
      - key: "{{ builder.id }}"
        operator: Equals
        value: "https://alauda.io/builders/tekton/v2"
        message: "The builder.id must be equal to https://alauda.io/builders/tekton/v2, not {{ builder.id }}"
```

```shell
$ kubectl run -n $NAMESPACE unbuilt --image=${IMAGE} -- sleep 3600
```

Receive the output like this, means the Pod is blocked by the policy.

```text
Error from server: admission webhook "mutate.kyverno.svc-fail" denied the request:

resource Pod/policy/unbuilt was blocked due to the following policies

verify-tekton-built-images:
  check-image: 'image attestations verification failed, verifiedCount: 0, requiredCount:
    1, error: .attestations[0].attestors[0].entries[0].keys: attestation checks failed
    for <registry>/test/chains/demo-1@sha256:93635f39cb31de5c6988cdf1f10435c41b3fb85570c930d51d41bbadc1a90046
    and predicate https://slsa.dev/provenance/v0.2: The builder.id must be equal to
    https://alauda.io/builders/tekton/v2, not https://alauda.io/builders/tekton/v1'
```

### Step 5: Clean up the resources

Delete the Pods created in the previous steps.

```shell
$ export NAMESPACE=<policy>
$ kubectl delete pod -n $NAMESPACE built
```

Delete the policy.

```shell
$ kubectl delete clusterpolicy verify-tekton-built-images
```

## Chapter 3. Enforcing Source Code Repository-based Image Deployment

In Tekton Chains, it can collect specific inputs and outputs from the `PipelineRun` and record them in the `SLSA Provenance`.

> See [Tekton Chains Type Hinting](#tekton-chains-type-hinting) in above section for more details.

We can use this feature to include the code repository information in the SLSA Provenance information. Then we can verify the code repository in kyverno.

This chapter explains how to implement the above process step by step.

### Step 1: Prerequisites

Please check if the prerequisites are completed, especially about this section:

- [Registry Configuration](#registry-configuration)
- [ServiceAccount Configuration](#serviceaccount-configuration)
- [Get the signing public key](#get-the-signing-public-key)
- [jq](https://stedolan.github.io/jq/)
  - To present the contents of the attestation in a friendly manner.

To avoid Tekton Chains generating SLSA Provenance for both TaskRun and PipelineRun, which will affect the verification of kyverno later, we first disable the SLSA Provenance for TaskRun.

> This process requires platform administrator privileges to configure.

```shell
$ kubectl patch tektonconfigs.operator.tekton.dev config --type=merge -p='{
  "spec": {
    "chain": {
      "artifacts.taskrun.storage": ""
    }
  }
}'
```

### Step 2: Adjust the pipeline to include the code repository information in the image source information

In the previous image build pipeline, add a `git` clone task, and save the output of the `git` task to the `results` of the `PipelineRun`.

```yaml
apiVersion: tekton.dev/v1
kind: Pipeline
metadata:
  name: chains-demo-3
spec:
  params:
    - default: |-
        echo "Simulate cloning the code and write the repository URL and commit message into the results."

        # This commit sha must be a valid commit sha [0-9a-f]{40}.
        cat << 'EOF' > $(results.array-result.path)
        [
          "https://github.com/tektoncd/pipeline",
          "cccccaaaa0000000000000000000000000000000"
        ]
        EOF

        echo -e "\nResults:"
        echo "-------------------"
        cat $(results.array-result.path)
        echo "-------------------"
        echo -e "\nClone successfully!"
      description: A script to simulate cloning the code and write the repository URL and commit message into the results.
      name: generate-git-clone-results
      type: string
    - default: |-
        echo "Generate a Dockerfile for building an image."

        cat << 'EOF' > Dockerfile
        FROM ubuntu:latest
        ENV TIME=1
        EOF

        echo -e "\nDockerfile contents:"
        echo "-------------------"
        cat Dockerfile
        echo "-------------------"
        echo -e "\nDockerfile generated successfully!"
      description: A script to generate a Dockerfile for building an image.
      name: generate-dockerfile
      type: string
    - default: <registry>/test/chains/demo-3:latest
      description: The target image address built
      name: image
      type: string
  results:
    - description: first image artifact output
      name: first_image_ARTIFACT_OUTPUTS
      type: object
      value:
        digest: $(tasks.build-image.results.IMAGE_DIGEST)
        uri: $(tasks.build-image.results.IMAGE_URL)
    - description: first repo artifact input
      name: source_repo_ARTIFACT_INPUTS
      type: object
      value:
        digest: sha1:$(tasks.git-clone.results.array-result[1])
        uri: $(tasks.git-clone.results.array-result[0])
  tasks:
    - name: git-clone
      params:
        - name: script
          value: $(params.generate-git-clone-results)
      taskRef:
        params:
          - name: kind
            value: task
          - name: catalog
            value: catalog
          - name: name
            value: run-script
          - name: version
            value: "0.1"
        resolver: hub
      timeout: 30m0s
      workspaces:
        - name: source
          workspace: source
    - name: generate-dockerfile
      params:
        - name: script
          value: $(params.generate-dockerfile)
      runAfter:
        - git-clone
      taskRef:
        params:
          - name: kind
            value: task
          - name: catalog
            value: catalog
          - name: name
            value: run-script
          - name: version
            value: "0.1"
        resolver: hub
      timeout: 30m0s
      workspaces:
        - name: source
          workspace: source
    - name: build-image
      params:
        - name: IMAGES
          value:
            - $(params.image)
        - name: TLS_VERIFY
          value: "false"
      runAfter:
        - generate-dockerfile
      taskRef:
        params:
          - name: kind
            value: task
          - name: catalog
            value: catalog
          - name: name
            value: buildah
          - name: version
            value: "0.9"
        resolver: hub
      timeout: 30m0s
      workspaces:
        - name: source
          workspace: source
        - name: dockerconfig
          workspace: dockerconfig
  workspaces:
    - name: source
      description: The workspace for source code.
    - name: dockerconfig
      description: The workspace for Docker configuration.
```

> **Note:**
>
> This tutorial demonstrates a simplified workflow by generating the `Dockerfile` and `git-clone` task output inline within the pipeline.
> In production environments, you would typically:
>
> 1. Use the `git-clone` task to fetch source code from your repository
> 2. Build the image using the Dockerfile that exists in your source code
> 3. This approach ensures proper version control and maintains the separation between code and pipeline configuration

**Explanation of YAML fields:**

- Most fields are the same as in [Chapter 1: Create a pipeline to build the image](#step-2-create-a-pipeline-to-generate-the-image). Below only introduces the differences.
- `params`
  - `generate-git-clone-results`: A script to simulate cloning the code and write the repository URL and commit message into the results.
- `results`
  - `source_repo_ARTIFACT_INPUTS`: The source code repository URL and commit message.
    - `digest`: The commit sha of the source code repository.
  - This format is compliant with Tekton Chains, see [Tekton Chains Type Hinting](#tekton-chains-type-hinting) in above section for more details.


### Step 3: Run the pipeline to generate the image

This is a PipelineRun resource, which is used to run the pipeline.

```yaml
apiVersion: tekton.dev/v1
kind: PipelineRun
metadata:
  generateName: chains-demo-3-
spec:
  pipelineRef:
    name: chains-demo-3
  taskRunTemplate:
    serviceAccountName: <default>
  workspaces:
    - name: dockerconfig
      secret:
        secretName: <registry-credentials>
    - name: source
      volumeClaimTemplate:
        spec:
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 1Gi
          storageClassName: <nfs>
```

**Explanation of YAML fields:**

- The same as in [Chapter 1: Run the pipeline to generate the image](#step-3-run-the-pipeline-to-generate-the-image).

Save into a yaml file named `chains.demo-3.pipelinerun.yaml` and apply it with:

```shell
$ export NAMESPACE=<default>

# create the pipeline run resource in the namespace
$ kubectl create -n $NAMESPACE -f chains.demo-3.pipelinerun.yaml
```

Wait for the PipelineRun to complete.

```shell
$ kubectl get pipelinerun -n $NAMESPACE -w

chains-demo-3-<xxxxx>   True        Succeeded   2m         2m
```

### Step 4: Wait for the pipeline to be signed

Wait for the PipelineRun has `chains.tekton.dev/signed: "true"` annotation.

```shell
$ export NAMESPACE=<default>
$ export PIPELINERUN_NAME=<chains-demo-3-xxxxx>

$ kubectl get pipelinerun -n $NAMESPACE $PIPELINERUN_NAME -o yaml | grep "chains.tekton.dev/signed"

    chains.tekton.dev/signed: "true"
```

Once the PipelineRun has `chains.tekton.dev/signed: "true"` annotation, means the image is signed.

### Step 5: Get the image from the PipelineRun

```shell
# Get the image URI
$ export IMAGE_URI=$(kubectl get pipelinerun -n $NAMESPACE $PIPELINERUN_NAME -o jsonpath='{.status.results[?(@.name=="first_image_ARTIFACT_OUTPUTS")].value.uri}')

# Get the image digest
$ export IMAGE_DIGEST=$(kubectl get pipelinerun -n $NAMESPACE $PIPELINERUN_NAME -o jsonpath='{.status.results[?(@.name=="first_image_ARTIFACT_OUTPUTS")].value.digest}')

# Combine the image URI and digest to form the full image reference
$ export IMAGE=$IMAGE_URI@$IMAGE_DIGEST

# Print the image reference
$ echo $IMAGE

<registry>/test/chains/demo-3:latest@sha256:db2607375049e8defa75a8317a53fd71fd3b448aec3c507de7179ded0d4b0f20
```

This image will be used to verify the code repository.

### Step 7: (Optional) Get the SLSA Provenance attestation

> **Tips:**:
>
> - If you interested about the SLSA Provenance attestation content, you can continue to read the following content.

Get the signing public key according to the [Get the signing public key](#get-the-signing-public-key) section.

```shell
# Disable tlog upload and enable private infrastructure
$ export COSIGN_TLOG_UPLOAD=false
$ export COSIGN_PRIVATE_INFRASTRUCTURE=true

$ export IMAGE=<<registry>/test/chains/demo-3:latest@sha256:db2607375049e8defa75a8317a53fd71fd3b448aec3c507de7179ded0d4b0f20>

$ cosign verify-attestation --key cosign.pub --type slsaprovenance $IMAGE | jq -r '.payload | @base64d' | jq -s
```

The output will be similar to the following, which contains the SLSA Provenance attestation.

```json
{
  "_type": "https://in-toto.io/Statement/v0.1",
  "subject": [
    {
      "name": "<registry>/test/chains/demo-3:latest",
      "digest": {
        "sha256": "db2607375049e8defa75a8317a53fd71fd3b448aec3c507de7179ded0d4b0f20"
      }
    }
  ],
  "predicateType": "https://slsa.dev/provenance/v0.2",
  "predicate": {
    "buildConfig": {
      "tasks": null
    },
    "buildType": "tekton.dev/v1beta1/PipelineRun",
    "builder": {
      "id": "https://alauda.io/builders/tekton/v1"
    },
    "invocation": {
      "parameters": {
        "image": "<registry>/test/chains/demo-3:latest"
      }
    },
    "materials": [
      {
        "digest": {
          "sha256": "bad5d84ded24307d12cacc9ef37fc38bce90ea5d00501f43b27d0c926be26f19"
        },
        "uri": "oci://<registry>/devops/tektoncd/hub/run-script"
      },
      {
        "digest": {
          "sha1": "cccccaaaa0000000000000000000000000000000"
        },
        "uri": "https://github.com/tektoncd/pipeline"
      }
    ],
    "metadata": {
      "buildFinishedOn": "2025-06-06T10:28:21Z",
      "buildStartedOn": "2025-06-06T10:27:34Z"
    }
  }
}
```

> More details about the SLSA Provenance attestation, please refer to [SLSA Provenance](https://slsa.dev/spec/v1.1/provenance)

**Description of the fields:**

- `predicateType`: The type of the predicate.
- `predicate`:
  - `buildConfig`:
    - `tasks`: The tasks of the build.
  - `buildType`: The type of the build, this is `tekton.dev/v1beta1/PipelineRun`.
  - `builder`:
    - `id`: The id of the builder, this is `https://alauda.io/builders/tekton/v1`.
  - `invocation`:
    - `parameters`: The parameters of the build.
  - `materials`: The materials of the build.
    - `uri`:
      - `oci://<registry>/devops/tektoncd/hub/run-script`: The image of the task used.
      - `https://github.com/tektoncd/pipeline`: The source code repository of the task.
  - `metadata`: The metadata of the build.
    - `buildFinishedOn`: The time when the build finished.
    - `buildStartedOn`: The time when the build started.

### Step 8: Verify image source repository restriction with Kyverno

The content of the provenance is roughly as follows, we will use the `materials` field to verify the code repository.

```json
{
  "_type": "https://in-toto.io/Statement/v0.1",
  "predicateType": "https://slsa.dev/provenance/v0.2",
  "predicate": {
    "buildType": "tekton.dev/v1beta1/PipelineRun",
    "builder": {
      "id": "https://alauda.io/builders/tekton/v1"
    },
    "materials": [
      {
        "digest": {
          "sha256": "bad5d84ded24307d12cacc9ef37fc38bce90ea5d00501f43b27d0c926be26f19"
        },
        "uri": "oci://<registry>/devops/tektoncd/hub/run-script"
      },
      {
        "digest": {
          "sha256": "7a63e6c2d1b4c118e9a974e7850dd3e9321e07feec8302bcbcd16653c512ac59"
        },
        "uri": "http://tekton-hub-api.tekton-pipelines:8000/v1/resource/catalog/task/run-script/0.1/yaml"
      },
      {
        "digest": {
          "sha256": "8d5ea9ecd9b531e798fecd87ca3b64ee1c95e4f2621d09e893c58ed593bfd4c4"
        },
        "uri": "oci://<registry>/devops/tektoncd/hub/buildah"
      },
      {
        "digest": {
          "sha256": "3225653d04c223be85d173747372290058a738427768c5668ddc784bf24de976"
        },
        "uri": "http://tekton-hub-api.tekton-pipelines:8000/v1/resource/catalog/task/buildah/0.9/yaml"
      },
      {
        "digest": {
          "sha1": "cccccaaaa0000000000000000000000000000000"
        },
        "uri": "https://github.com/tektoncd/pipeline"
      }
    ],
    "metadata": {
      "buildFinishedOn": "2025-06-06T10:21:27Z",
      "buildStartedOn": "2025-06-06T10:20:38Z"
    }
  }
}
```

#### Step 8.1: Create a Kyverno policy to allow only images built from specific source code repositories to be deployed

The policy is as follows:

```yaml
apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: verify-code-repository-material
spec:
  webhookConfiguration:
    failurePolicy: Fail
    timeoutSeconds: 30
  background: false
  rules:
    - name: check-image
      match:
        any:
          - resources:
              kinds:
                - Pod
              namespaces:
                - policy
      verifyImages:
        - imageReferences:
            - "*"
            # - "<registry>/test/*"
          skipImageReferences:
            - "ghcr.io/trusted/*"
          failureAction: Enforce
          verifyDigest: false
          required: false
          useCache: false
          imageRegistryCredentials:
            allowInsecureRegistry: true
            secrets:
              # The credential needs to exist in the namespace where kyverno is deployed
              - registry-credentials

          attestations:
            - type: https://slsa.dev/provenance/v0.2
              attestors:
                - entries:
                    - keys:
                        publicKeys: |- # <- The public key of the signer
                          -----BEGIN PUBLIC KEY-----
                          MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEFZNGfYwn7+b4uSdEYLKjxWi3xtP3
                          UkR8hQvGrG25r0Ikoq0hI3/tr0m7ecvfM75TKh5jGAlLKSZUJpmCGaTToQ==
                          -----END PUBLIC KEY-----

                        ctlog:
                          ignoreSCT: true

                        rekor:
                          ignoreTlog: true
              conditions:
                - all:
                    - key: "{{ buildType }}"
                      operator: Equals
                      value: "tekton.dev/v1beta1/PipelineRun"
                      message: "The buildType must be equal to tekton.dev/v1beta1/PipelineRun, not {{ buildType }}"

                    - key: "{{ materials[?starts_with(uri, 'https://github.com/tektoncd/')] | length(@) }}"
                      operator: GreaterThan
                      value: 0
                      message: "The materials must have at least one entry starts with https://github.com/tektoncd/, {{ materials }}"
```

> More details about Kyverno ClusterPolicy, please refer to [Kyverno ClusterPolicy](https://kyverno.io/docs/policy-types/cluster-policy/)

**Explanation of YAML fields**

- The policy is largely consistent with the one in [Chapter 1: Create a Kyverno policy to allow only signed images to be deployed](#step-71-create-a-kyverno-policy-to-allow-only-signed-images-to-be-deployed)
- `spec.rules[].verifyImages[].attestations[].conditions`: The conditions to verify.
  - `all`: The all conditions must be met.
    - `key: "{{ buildType }}"`: The build type must be equal to `tekton.dev/v1beta1/PipelineRun`.
    - `key: "{{ materials[?starts_with(uri, 'https://github.com/tektoncd/')] | length(@) }}"`: The materials must have at least one entry starts with `https://github.com/tektoncd/`.

Save into a yaml file named `verify-code-repository-material.yaml` and apply it with:

```shell
$ kubectl create -f verify-code-repository-material.yaml

clusterpolicy.kyverno.io/verify-code-repository-material created
```

#### Step 8.2: Verify the policy

In the `policy` namespace where the policy is defined, create a Pod to verify the policy.

Use the built image to create a Pod.

```shell
$ export NAMESPACE=<policy>
$ export IMAGE=<<registry>/test/chains/demo-3:latest@sha256:db2607375049e8defa75a8317a53fd71fd3b448aec3c507de7179ded0d4b0f20>

$ kubectl run -n $NAMESPACE built-from-specific-repo --image=${IMAGE} -- sleep 3600

pod/built-from-specific-repo created
```

The Pod will be created successfully.

```shell
$ kubectl get pod -n $NAMESPACE built-from-specific-repo

NAME                      READY   STATUS    RESTARTS   AGE
built-from-specific-repo   1/1     Running   0          10s
```

Change the code repository in the `ClusterPolicy` to an other value `https://gitlab.com/`, and verify again.

```yaml
conditions:
  - all:
      - key: "{{ buildType }}"
        operator: Equals
        value: "tekton.dev/v1beta1/PipelineRun"
        message: "The buildType must be equal to tekton.dev/v1beta1/PipelineRun, not {{ buildType }}"

      - key: "{{ materials[?starts_with(uri, 'https://gitlab.com/')] | length(@) }}"
        operator: GreaterThan
        value: 0
        message: "The materials must have at least one entry starts with https://gitlab.com/, {{ materials }}"
```


```shell
$ kubectl run -n $NAMESPACE unbuilt-from-specific-repo --image=${IMAGE} -- sleep 3600
```

Receive the output like this, means the Pod is blocked by the policy.

```text
Error from server: admission webhook "mutate.kyverno.svc-fail" denied the request:

resource Pod/policy/unbuilt-from-specific-repo was blocked due to the following policies

verify-code-repository-material:
  check-image: 'image attestations verification failed, verifiedCount: 0, requiredCount:
    1, error: .attestations[0].attestors[0].entries[0].keys: attestation checks failed
    for <registry>/test/chains/demo-3:latest and predicate https://slsa.dev/provenance/v0.2:
    The materials must have at least one entry starts with https://gitlab.com/,
    [{"digest":{"sha256":"bad5d84ded24307d12cacc9ef37fc38bce90ea5d00501f43b27d0c926be26f19"},"uri":"oci://<registry>/devops/tektoncd/hub/run-script"},{"digest":{"sha256":"7a63e6c2d1b4c118e9a974e7850dd3e9321e07feec8302bcbcd16653c512ac59"},"uri":"http://tekton-hub-api.tekton-pipelines:8000/v1/resource/catalog/task/run-script/0.1/yaml"},{"digest":{"sha256":"8d5ea9ecd9b531e798fecd87ca3b64ee1c95e4f2621d09e893c58ed593bfd4c4"},"uri":"oci://<registry>/devops/tektoncd/hub/buildah"},{"digest":{"sha256":"3225653d04c223be85d173747372290058a738427768c5668ddc784bf24de976"},"uri":"http://tekton-hub-api.tekton-pipelines:8000/v1/resource/catalog/task/buildah/0.9/yaml"},{"digest":{"sha1":"cccccaaaa0000000000000000000000000000000"},"uri":"https://github.com/tektoncd/pipeline"}]'
```

### Step 9: Clean up the resources

Delete the Pods created in the previous steps.

```shell
$ export NAMESPACE=<policy>
$ kubectl delete pod -n $NAMESPACE built-from-specific-repo
```

Delete the policy.

```shell
$ kubectl delete clusterpolicy verify-code-repository-material
```

## Chapter 4. Preventing Deployment of Images with Critical Security Vulnerabilities

In ACP (Alauda Container Platform), you can use Tekton Pipeline to build and scan the image for vulnerabilities.

Specifically, use the `trivy` task to generate vulnerability scan results, then use `cosign` to upload the attestation of the vulnerability scan results, and finally use `kyverno` to validate the attestation of the vulnerability scan results.

This chapter explains how to implement the above process step by step.

### Step 1: Prerequisites

Please check if the prerequisites are completed, especially about this section:

- [Registry Configuration](#registry-configuration)
- [ServiceAccount Configuration](#serviceaccount-configuration)
- [Get the signing public key](#get-the-signing-public-key)
- [Get the signing secret](#get-the-signing-secret)
  - **Important**: This is only for convenience, so the global signing certificate of Chains is used here. In actual use, you can use a separate certificate to sign the image vulnerability information.
  - Import the secret into the namespace where the pipeline is executed.
- [jq](https://stedolan.github.io/jq/)
  - To present the contents of the attestation in a friendly manner.

### Step 2: Create a pipeline to generate cosign vuln attestation

This is a Pipeline resource, which is used to build the image and generate the cosign vuln attestation.

```yaml
apiVersion: tekton.dev/v1
kind: Pipeline
metadata:
  name: chains-demo-4
spec:
  params:
    - default: |-
        echo "Generate a Dockerfile for building an image."

        cat << 'EOF' > Dockerfile
        FROM ubuntu:latest
        ENV TIME=1
        EOF

        echo -e "\nDockerfile contents:"
        echo "-------------------"
        cat Dockerfile
        echo "-------------------"
        echo -e "\nDockerfile generated successfully!"
      description: A script to generate a Dockerfile for building an image.
      name: generate-dockerfile
      type: string
    - default: <registry>/test/chains/demo-4:latest
      description: The target image address built
      name: image
      type: string
  results:
    - description: first image artifact output
      name: first_image_ARTIFACT_OUTPUTS
      type: object
      value:
        digest: $(tasks.build-image.results.IMAGE_DIGEST)
        uri: $(tasks.build-image.results.IMAGE_URL)
  tasks:
    - name: generate-dockerfile
      params:
        - name: script
          value: $(params.generate-dockerfile)
      taskRef:
        params:
          - name: kind
            value: task
          - name: catalog
            value: catalog
          - name: name
            value: run-script
          - name: version
            value: "0.1"
        resolver: hub
      timeout: 30m0s
      workspaces:
        - name: source
          workspace: source
    - name: build-image
      params:
        - name: IMAGES
          value:
            - $(params.image)
        - name: TLS_VERIFY
          value: "false"
      runAfter:
        - generate-dockerfile
      taskRef:
        params:
          - name: kind
            value: task
          - name: catalog
            value: catalog
          - name: name
            value: buildah
          - name: version
            value: "0.9"
        resolver: hub
      timeout: 30m0s
      workspaces:
        - name: source
          workspace: source
        - name: dockerconfig
          workspace: dockerconfig
    - name: trivy-scanner
      params:
        - name: COMMAND
          value: |-
            set -x

            mkdir -p .git

            # support for insecure registry
            export TRIVY_INSECURE=true

            echo "generate cyclonedx sbom"
            trivy image --skip-db-update --skip-java-db-update --scanners vuln --format cyclonedx --output .git/sbom-cyclonedx.json $(tasks.build-image.results.IMAGE_URL)@$(tasks.build-image.results.IMAGE_DIGEST)
            cat .git/sbom-cyclonedx.json

            echo "trivy scan vulnerabilities based on cyclonedx sbom"
            trivy sbom --skip-db-update --skip-java-db-update --format cosign-vuln --output .git/trivy-scan-result.json .git/sbom-cyclonedx.json
            cat .git/trivy-scan-result.json

            echo "trivy scan vulnerabilities based on cyclonedx sbom and output in table format"
            trivy sbom --skip-db-update --skip-java-db-update --format table .git/sbom-cyclonedx.json
      runAfter:
        - build-image
      taskRef:
        params:
          - name: kind
            value: task
          - name: catalog
            value: catalog
          - name: name
            value: trivy-scanner
          - name: version
            value: "0.4"
        resolver: hub
      timeout: 30m0s
      workspaces:
        - name: source
          workspace: source
        - name: dockerconfig
          workspace: dockerconfig
    - name: cosign-uploads
      params:
        - name: COMMAND
          value: |-
            set -x

            export COSIGN_ALLOW_INSECURE_REGISTRY=true
            export COSIGN_TLOG_UPLOAD=false
            export COSIGN_KEY=$(workspaces.signkey.path)/cosign.key

            echo "Signing image vuln"
            cosign attest --type vuln --predicate .git/trivy-scan-result.json $(tasks.build-image.results.IMAGE_URL)@$(tasks.build-image.results.IMAGE_DIGEST)

            echo "Signing image sbom"
            cosign attest --type cyclonedx --predicate .git/sbom-cyclonedx.json $(tasks.build-image.results.IMAGE_URL)@$(tasks.build-image.results.IMAGE_DIGEST)
      runAfter:
        - trivy-scanner
      taskRef:
        params:
          - name: kind
            value: task
          - name: catalog
            value: catalog
          - name: name
            value: cosign
          - name: version
            value: "0.1"
        resolver: hub
      timeout: 30m0s
      workspaces:
        - name: source
          workspace: source
        - name: dockerconfig
          workspace: dockerconfig
        - name: signkey
          workspace: signkey
  workspaces:
    - name: source
      description: The workspace for source code.
    - name: dockerconfig
      description: The workspace for Docker configuration.
    - name: signkey
      description: The workspace for private keys and passwords used for image signatures.
```

**Explanation of YAML fields:**

- The same as in [Chapter 1: Create a pipeline to generate the image](#step-2-create-a-pipeline-to-generate-the-image), but adds the following content:
  - `workspaces`:
    - `signkey`: The workspace for private keys and passwords used for image signatures.
  - `tasks`:
    - `trivy-scanner`: The task to scan the image for vulnerabilities.
    - `cosign-uploads`: The task to upload the attestation of the vulnerability scan results.

Save into a yaml file named `chains-demo-4.yaml` and apply it with:

```shell
$ export NAMESPACE=<default>

# create the pipeline in the namespace
$ kubectl create -n $NAMESPACE -f chains-demo-4.yaml

pipeline.tekton.dev/chains-demo-4 created
```

### Step 3: Run the pipeline to generate cosign vuln attestation

This is a PipelineRun resource, which is used to run the pipeline.

```yaml
apiVersion: tekton.dev/v1
kind: PipelineRun
metadata:
  generateName: chains-demo-4-
spec:
  pipelineRef:
    name: chains-demo-4
  taskRunTemplate:
    serviceAccountName: <default>
  workspaces:
    - name: dockerconfig
      secret:
        secretName: <registry-credentials>
    - name: signkey
      secret:
        secretName: <signing-secrets>
    - name: source
      volumeClaimTemplate:
        spec:
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 1Gi
          storageClassName: <nfs>
```

**Explanation of YAML fields:**

- The same as in [Chapter 1: Run the pipeline to generate the image](#step-3-run-the-pipeline-to-generate-the-image). Below only introduces the differences.
- `workspaces`
  - `signkey`: the secret name of the signing key.
    - `secret.secretName`: The signing secret prepared in the previous step [Get the signing secret](#get-the-signing-secret). But you need to create a new secret with the same namespace as the pipeline run.

Save into a yaml file named `chains-demo-4.pipelinerun.yaml` and apply it with:

```shell
$ export NAMESPACE=<default>

# create the pipeline run in the namespace
$ kubectl create -n $NAMESPACE -f chains-demo-4.pipelinerun.yaml
```

Wait for the PipelineRun to be completed.

```shell
$ kubectl get pipelinerun -n $NAMESPACE -w

chains-demo-4-<xxxxx>     True        Succeeded   2m  2m
```

### Step 4: Get the image from the pipelinerun
> **Same as [Chapter 1: Get the image from the pipelinerun](#step-5-get-the-image-from-the-pipelinerun)**

### Step 5: (Optional) Get the cosign vuln attestation

> **Tips:**:
>
> - If you interested about the cosign vuln attestation content, you can continue to read the following content.

Get the signing public key according to the [Get the signing public key](#get-the-signing-public-key) section.

```shell
# Disable tlog upload and enable private infrastructure
$ export COSIGN_TLOG_UPLOAD=false
$ export COSIGN_PRIVATE_INFRASTRUCTURE=true

$ export IMAGE=<<registry>/test/chains/demo-4:latest@sha256:5e7b466e266633464741b61b9746acd7d02c682d2e976b1674f924aa0dfa2047>

$ cosign verify-attestation --key cosign.pub --type vuln $IMAGE | jq -r '.payload | @base64d' | jq -s
```

The output will be similar to the following, which contains the vulnerability scan results.

```json
{
  "_type": "https://in-toto.io/Statement/v0.1",
  "predicateType": "https://cosign.sigstore.dev/attestation/vuln/v1",
  "predicate": {
    "scanner": {
      "uri": "pkg:github/aquasecurity/trivy@dev",
      "version": "dev",
      "result": {
        "CreatedAt": "2025-06-07T07:05:30.098889688Z",
        "Metadata": {
          "OS": {
            "Family": "ubuntu",
            "Name": "24.04"
          }
        },
        "Results": [
          {
            "Class": "os-pkgs",
            "Packages": [
              {
                "Arch": "amd64",
                "ID": "coreutils@9.4-3ubuntu6",
                "Identifier": {
                  "BOMRef": "pkg:deb/ubuntu/coreutils@9.4-3ubuntu6?arch=amd64&distro=ubuntu-24.04",
                  "PURL": "pkg:deb/ubuntu/coreutils@9.4-3ubuntu6?arch=amd64&distro=ubuntu-24.04",
                  "UID": "82bb3c93286700bc"
                },
                "Licenses": [
                  "GPL-3.0-or-later",
                  "BSD-4-Clause-UC",
                  "GPL-3.0-only",
                  "ISC",
                  "FSFULLR",
                  "GFDL-1.3-no-invariants-only",
                  "GFDL-1.3-only"
                ],
                "Name": "coreutils"
              }
            ],
            "Vulnerabilities": [
              {
                "CVSS": {
                  "nvd": {
                    "V2Score": 2.1,
                    "V2Vector": "AV:L/AC:L/Au:N/C:N/I:P/A:N",
                    "V3Score": 6.5,
                    "V3Vector": "CVSS:3.0/AV:L/AC:L/PR:L/UI:N/S:C/C:N/I:H/A:N"
                  },
                  "redhat": {
                    "V2Score": 6.2,
                    "V2Vector": "AV:L/AC:H/Au:N/C:C/I:C/A:C",
                    "V3Score": 8.6,
                    "V3Vector": "CVSS:3.0/AV:L/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H"
                  }
                },
                "InstalledVersion": "9.4-3ubuntu6",
                "LastModifiedDate": "2025-04-20T01:37:25.86Z",
                "PkgID": "coreutils@9.4-3ubuntu6",
                "PkgName": "coreutils",
                "PublishedDate": "2017-02-07T15:59:00.333Z",
                "References": [
                  "http://seclists.org/oss-sec/2016/q1/452",
                  "http://www.openwall.com/lists/oss-security/2016/02/28/2",
                  "http://www.openwall.com/lists/oss-security/2016/02/28/3",
                  "https://access.redhat.com/security/cve/CVE-2016-2781",
                  "https://lists.apache.org/thread.html/rf9fa47ab66495c78bb4120b0754dd9531ca2ff0430f6685ac9b07772%40%3Cdev.mina.apache.org%3E",
                  "https://lore.kernel.org/patchwork/patch/793178/",
                  "https://mirrors.edge.kernel.org/pub/linux/utils/util-linux/v2.28/v2.28-ReleaseNotes",
                  "https://nvd.nist.gov/vuln/detail/CVE-2016-2781",
                  "https://www.cve.org/CVERecord?id=CVE-2016-2781"
                ],
                "Severity": "LOW",
                "SeveritySource": "ubuntu",
                "Status": "affected",
                "VendorSeverity": {
                  "azure": 2,
                  "cbl-mariner": 2,
                  "nvd": 2,
                  "redhat": 2,
                  "ubuntu": 1
                },
                "VulnerabilityID": "CVE-2016-2781"
              }
            ]
          }
        ],
        "SchemaVersion": 2
      }
    },
    "metadata": {
      "scanStartedOn": "2025-06-07T07:05:30.104726629Z",
      "scanFinishedOn": "2025-06-07T07:05:30.104726629Z"
    }
  }
}
```

> More details about the cosign vuln attestation, please refer to [cosign vuln attestation](https://github.com/sigstore/cosign/blob/main/specs/COSIGN_VULN_ATTESTATION_SPEC.md)

**Description of the fields:**

- `predicateType`: The type of the predicate.
- `predicate.scanner`:
  - `uri`: The URI of the scanner.
  - `version`: The version of the scanner.
  - `result`: The result of the vulnerability scan.
    - `CreatedAt`: The time when the vulnerability scan finished.
    - `Metadata`:
      - `OS`:
        - `Family`: The family of the OS.
        - `Name`: The name of the OS.
    - `Results`: The results of the vulnerability scan.
      - `Class`:
        - `os-pkgs`: The OS packages.
        - `lang-pkgs`: The language packages.
      - `Packages`: The packages of the image.
      - `Vulnerabilities`: The vulnerabilities of the image.
        - `Severity`: The severity of the vulnerability.
        - `PkgID`: The package id of the vulnerability.
        - `PkgName`: The package name of the vulnerability.
        - `CVSS`: The CVSS of the vulnerability.
          - `nvd`: The NVD of the vulnerability.
          - `redhat`: The Red Hat of the vulnerability.

### Step 6: Verify the vulnerability scan results with Kyverno

#### Step 6.1: Create a Kyverno policy to reject images with high-risk vulnerabilities

> This step requires cluster administrator privileges.

The policy is as follows:

```yaml
apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: reject-high-risk-image
spec:
  webhookConfiguration:
    failurePolicy: Fail
    timeoutSeconds: 30
  background: false
  rules:
    - name: check-image
      match:
        any:
          - resources:
              kinds:
                - Pod
              namespaces:
                - policy
      verifyImages:
        - imageReferences:
            - "*"
            # - "<registry>/test/*"
          skipImageReferences:
            - "ghcr.io/trusted/*"
          failureAction: Enforce
          verifyDigest: false
          required: false
          useCache: false
          imageRegistryCredentials:
            allowInsecureRegistry: true
            secrets:
              # The credential needs to exist in the namespace where kyverno is deployed
              - registry-credentials

          attestations:
            - type: https://cosign.sigstore.dev/attestation/vuln/v1
              attestors:
                - entries:
                    - attestor:
                      keys:
                        publicKeys: |- # <- The public key of the signer
                          -----BEGIN PUBLIC KEY-----
                          MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEFZNGfYwn7+b4uSdEYLKjxWi3xtP3
                          UkR8hQvGrG25r0Ikoq0hI3/tr0m7ecvfM75TKh5jGAlLKSZUJpmCGaTToQ==
                          -----END PUBLIC KEY-----

                        ctlog:
                          ignoreSCT: true

                        rekor:
                          ignoreTlog: true

              conditions:
                - all:
                    - key: "{{ scanner.result.Results[].Vulnerabilities[].Severity }}"
                      operator: AllNotIn
                      # supported values: UNKNOWN, LOW, MEDIUM, HIGH, CRITICAL
                      value: ["HIGH", "CRITICAL"]
                      message: |
                        The image contains high-risk vulnerabilities, please fix them before proceeding.
                        Severity levels: {{ scanner.result.Results[].Vulnerabilities[].Severity }}

                    - key: "{{ scanner.result.Results[].Vulnerabilities[?CVSS.redhat.V3Score > `1.0`][] | length(@) }}"
                      operator: Equals
                      value: 0
                      message: |
                        The image contains high-risk vulnerabilities, please fix them before proceeding.
                        High-risk vulnerabilities (CVSS > 1.0): {{ scanner.result.Results[].Vulnerabilities[?CVSS.redhat.V3Score > `1.0`].CVSS.redhat.V3Score[] }}.
                        Severity levels: {{ scanner.result.Results[].Vulnerabilities[?CVSS.redhat.V3Score > `1.0`].Severity[] }}.
                        PkgIDs: {{ scanner.result.Results[].Vulnerabilities[?CVSS.redhat.V3Score > `1.0`].PkgID[] }}.
```

> More details about Kyverno ClusterPolicy, please refer to [Kyverno ClusterPolicy](https://kyverno.io/docs/policy-types/cluster-policy/)

**Explanation of YAML fields:**

- The policy is largely consistent with the one in [Chapter 1: Create a Kyverno policy to allow only signed images to be deployed](#step-71-create-a-kyverno-policy-to-allow-only-signed-images-to-be-deployed). Below only introduces the differences.
- `spec.rules[0].verifyImages[].attestations[0].conditions`
  - `type`: The cosign vuln attestation type is `https://cosign.sigstore.dev/attestation/vuln/v1`
  - `attestors`: the same as above.
  - `conditions`: The conditions to be verified.
    - `all`: All conditions must be met.
      - `key: "{{ scanner.result.Results[].Vulnerabilities[].Severity }}"`: The severity of the vulnerabilities must not be `HIGH` or `CRITICAL`.
      - `key: "{{ scanner.result.Results[].Vulnerabilities[?CVSS.redhat.V3Score > `1.0`][] | length(@) }}"`: The number of vulnerabilities with CVSS score greater than 1.0 must be 0.

Save the policy to a yaml file named `kyverno.reject-high-risk-image.yaml` and apply it with:

```shell
$ kubectl apply -f kyverno.reject-high-risk-image.yaml

clusterpolicy.kyverno.io/reject-high-risk-image configured
```

#### Step 6.2: Verify the policy

In the `policy` namespace where the policy is defined, create a Pod to verify the policy.

Use the built image to create a Pod.

```shell
$ export NAMESPACE=<policy>
$ export IMAGE=<<registry>/test/chains/demo-4:latest@sha256:0f123204c44969876ed12f40066ccccbfd68361f68c91eb313ac764d59428bef>

$ kubectl run -n $NAMESPACE vuln-image --image=${IMAGE} -- sleep 3600
```

If your image has high-risk vulnerabilities, the Pod will be blocked by the policy.
Receive the output like this:

```text
Error from server: admission webhook "mutate.kyverno.svc-fail" denied the request:

resource Pod/policy/high-risk was blocked due to the following policies

reject-high-risk-image:
  check-image: |
    image attestations verification failed, verifiedCount: 0, requiredCount: 1, error: .attestations[0].attestors[0].entries[0].keys: attestation checks failed for <registry>/test/chains/demo-4:latest and predicate https://cosign.sigstore.dev/attestation/vuln/v1: The image contains high-risk vulnerabilities, please fix them before proceeding.
    High-risk vulnerabilities (CVSS > 1.0): [8.6,2.7,6.2,5.9,7.5,4.7,7.4,4.7,7.4,4.7,7.4,4.7,7.4,5.9,3.6,3.6,7.3,4.4,6.5,5.4].
    Severity levels: ["LOW","MEDIUM","LOW","LOW","MEDIUM","MEDIUM","MEDIUM","MEDIUM","MEDIUM","MEDIUM","MEDIUM","MEDIUM","MEDIUM","LOW","LOW","LOW","MEDIUM","MEDIUM","MEDIUM","MEDIUM"].
    PkgIDs: ["coreutils@9.4-3ubuntu6","gpgv@2.4.4-2ubuntu17","gpgv@2.4.4-2ubuntu17","libgcrypt20@1.10.3-2build1","liblzma5@5.6.1+really5.4.5-1build0.1","libpam-modules@1.5.3-5ubuntu5.1","libpam-modules@1.5.3-5ubuntu5.1","libpam-modules-bin@1.5.3-5ubuntu5.1","libpam-modules-bin@1.5.3-5ubuntu5.1","libpam-runtime@1.5.3-5ubuntu5.1","libpam-runtime@1.5.3-5ubuntu5.1","libpam0g@1.5.3-5ubuntu5.1","libpam0g@1.5.3-5ubuntu5.1","libssl3t64@3.0.13-0ubuntu3.5","login@1:4.13+dfsg1-4ubuntu3.2","passwd@1:4.13+dfsg1-4ubuntu3.2","perl-base@5.38.2-3.2build2.1","golang.org/x/net@v0.23.0","golang.org/x/net@v0.23.0","stdlib@v1.22.12"].
```

Change the conditions in the `ClusterPolicy` to allow images with high-risk vulnerabilities, but the CVSS score is less than 10.0.

```yaml
conditions:
  - all:
      - key: "{{ scanner.result.Results[].Vulnerabilities[].Severity }}"
        operator: AllNotIn
        value: ["CRITICAL"]
        message: |
          The image contains high-risk vulnerabilities, please fix them before proceeding.
          Severity levels: {{ scanner.result.Results[].Vulnerabilities[].Severity }}

      - key: "{{ scanner.result.Results[].Vulnerabilities[?CVSS.redhat.V3Score > `10.0`][] | length(@) }}"
        operator: Equals
        value: 0
        message: |
          The image contains high-risk vulnerabilities, please fix them before proceeding.
          High-risk vulnerabilities (CVSS > 10.0): {{ scanner.result.Results[].Vulnerabilities[?CVSS.redhat.V3Score > `10.0`].CVSS.redhat.V3Score[] }}.
          Severity levels: {{ scanner.result.Results[].Vulnerabilities[?CVSS.redhat.V3Score > `10.0`].Severity[] }}.
          PkgIDs: {{ scanner.result.Results[].Vulnerabilities[?CVSS.redhat.V3Score > `10.0`].PkgID[] }}.
```

Then create a Pod again to verify the policy.

```shell
$ kubectl run -n $NAMESPACE vuln-image --image=${IMAGE} -- sleep 3600

pod/vuln-image created
```

The Pod will be created successfully.

### Step 7: (Optional) Require the vulnerability scan results to be within 168 hours

> **Tips:**:
>
> - If you interested to add more conditions to the policy, you can continue to read the following content.

Since the [Cosign Vulnerability Scan Record Attestation](https://github.com/sigstore/cosign/blob/main/specs/COSIGN_VULN_ATTESTATION_SPEC.md) includes a `scanFinishedOn` field,
and the `trivy` meets the specifications, we can use this field to determine if the vulnerability scan results are within 168 hours.

We only need to add a condition to the `ClusterPolicy` to check if the `scanFinishedOn` field is within 168 hours.

```yaml
conditions:
  - all:
      - key: "{{ time_since('','{{metadata.scanFinishedOn}}','') }}"
        operator: LessThanOrEquals
        value: "168h"
        message: "The vulnerability scan results must be within 168 hours, not {{ metadata.scanFinishedOn }}"
```

This is not demonstrated here, interested readers can try it themselves.

### Step 8: Clean up the resources

Delete the Pods created in the previous steps.

```shell
$ export NAMESPACE=<policy>
$ kubectl delete pod -n $NAMESPACE vuln-image
```

Delete the policy.

```shell
$ kubectl delete clusterpolicy reject-high-risk-image
```

## Chapter 5. Base Image Allowlist Verification

If we want to allow only specific types of base images to be deployed,
we can save that information into the image attestation after obtaining it.

In [Chapter 4](#chapter-4-preventing-deployment-of-images-with-critical-security-vulnerabilities), the `cosign-vuln` format attestations already include the base image information.
But here we will use a different approach, using `syft` to generate the SBOM for the image.
The SBOM information also includes the base image information.

In ACP (Alauda Container Platform), you can use `trivy` or `syft` task in Tekton Pipeline to generate the SBOM for image.
Here we use the syft task to generate SBOM.

### Step 1: Prerequisites

Please check if the prerequisites are completed, especially about this section:

- [Registry Configuration](#registry-configuration)
- [ServiceAccount Configuration](#serviceaccount-configuration)
- [Get the signing public key](#get-the-signing-public-key)
- [Get the signing secret](#get-the-signing-secret)
  - **Important**: This is only for convenience, so the global signing certificate of Chains is used here. In actual use, you can use a separate certificate to sign the image vulnerability information.
  - Import the secret into the namespace where the pipeline is executed.
- [jq](https://stedolan.github.io/jq/)
  - To present the contents of the attestation in a friendly manner.

### Step 2: Create a pipeline to generate SBOM

This is a Pipeline resource, which is used to build the image and generate the SBOM.

```yaml
apiVersion: tekton.dev/v1
kind: Pipeline
metadata:
  name: chains-demo-5
spec:
  params:
    - default: |-
        echo "Generate a Dockerfile for building an image."

        cat << 'EOF' > Dockerfile
        FROM ubuntu:latest
        ENV TIME=1
        EOF

        echo -e "\nDockerfile contents:"
        echo "-------------------"
        cat Dockerfile
        echo "-------------------"
        echo -e "\nDockerfile generated successfully!"
      description: A script to generate a Dockerfile for building an image.
      name: generate-dockerfile
      type: string
    - default: <registry>/test/chains/demo-5:latest
      description: The target image address built
      name: image
      type: string
  results:
    - description: first image artifact output
      name: first_image_ARTIFACT_OUTPUTS
      type: object
      value:
        digest: $(tasks.build-image.results.IMAGE_DIGEST)
        uri: $(tasks.build-image.results.IMAGE_URL)
  tasks:
    - name: generate-dockerfile
      params:
        - name: script
          value: $(params.generate-dockerfile)
      taskRef:
        params:
          - name: kind
            value: task
          - name: catalog
            value: catalog
          - name: name
            value: run-script
          - name: version
            value: "0.1"
        resolver: hub
      timeout: 30m0s
      workspaces:
        - name: source
          workspace: source
    - name: build-image
      params:
        - name: IMAGES
          value:
            - $(params.image)
        - name: TLS_VERIFY
          value: "false"
      runAfter:
        - generate-dockerfile
      taskRef:
        params:
          - name: kind
            value: task
          - name: catalog
            value: catalog
          - name: name
            value: buildah
          - name: version
            value: "0.9"
        resolver: hub
      timeout: 30m0s
      workspaces:
        - name: source
          workspace: source
        - name: dockerconfig
          workspace: dockerconfig
    - name: syft-sbom
      params:
        - name: COMMAND
          value: |-
            set -x

            mkdir -p .git

            echo "Generate sbom.json"
            syft scan $(tasks.build-image.results.IMAGE_URL)@$(tasks.build-image.results.IMAGE_DIGEST) -o cyclonedx-json=.git/sbom.json > /dev/null

            echo -e "\n\n"
            cat .git/sbom.json
            echo -e "\n\n"

            echo "Generate and Attestation sbom"
            syft attest $(tasks.build-image.results.IMAGE_URL)@$(tasks.build-image.results.IMAGE_DIGEST) -o cyclonedx-json
      runAfter:
        - build-image
      taskRef:
        params:
          - name: kind
            value: task
          - name: catalog
            value: catalog
          - name: name
            value: syft
          - name: version
            value: "0.1"
        resolver: hub
      timeout: 30m0s
      workspaces:
        - name: source
          workspace: source
        - name: dockerconfig
          workspace: dockerconfig
        - name: signkey
          workspace: signkey
  workspaces:
    - name: source
      description: The workspace for source code.
    - name: dockerconfig
      description: The workspace for Docker configuration.
    - name: signkey
      description: The workspace for private keys and passwords used for image signatures.
```

**Explanation of YAML fields:**

- The same as in [Chapter 1: Create a pipeline to generate the image](#step-2-create-a-pipeline-to-generate-the-image), but adds the following content:
  - `workspaces`:
    - `signkey`: The workspace for private keys and passwords used for image signatures.
  - `tasks`:
    - `syft-sbom`: The task to generate the SBOM for the image and upload the attestation.

### Step 3: Run the pipeline to generate cosign vuln attestation

This is a PipelineRun resource, which is used to run the pipeline.

```yaml
apiVersion: tekton.dev/v1
kind: PipelineRun
metadata:
  generateName: chains-demo-5-
spec:
  pipelineRef:
    name: chains-demo-5
  taskRunTemplate:
    serviceAccountName: <default>
  workspaces:
    - name: dockerconfig
      secret:
        secretName: <registry-credentials>
    - name: source
      volumeClaimTemplate:
        spec:
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 1Gi
          storageClassName: <nfs>
```

**Explanation of YAML fields:**

- The same as in [Chapter 1: Run the pipeline to generate the image](#step-3-run-the-pipeline-to-generate-the-image). Below only introduces the differences.
- `workspaces`
  - `signkey`: the secret name of the signing key.
    - `secret.secretName`: The signing secret prepared in the previous step [Get the signing secret](#get-the-signing-secret). But you need to create a new secret with the same namespace as the pipeline run.

Save into a yaml file named `chains-demo-5.pipelinerun.yaml` and apply it with:

```shell
$ export NAMESPACE=<default>

# create the pipeline run in the namespace
$ kubectl create -n $NAMESPACE -f chains-demo-5.pipelinerun.yaml
```

Wait for the PipelineRun to be completed.

```shell
$ kubectl get pipelinerun -n $NAMESPACE -w

chains-demo-5-<xxxxx>     True        Succeeded   2m  2m
```

### Step 4: Get the image from the pipelinerun
> **Same as [Chapter 1: Get the image from the pipelinerun](#step-5-get-the-image-from-the-pipelinerun)**

### Step 5: (Optional) Get the SBOM attestation

> **Tips:**:
>
> - If you interested about the SBOM attestation content, you can continue to read the following content.

Get the signing public key according to the [Get the signing public key](#get-the-signing-public-key) section.

```shell
# Disable tlog upload and enable private infrastructure
$ export COSIGN_TLOG_UPLOAD=false
$ export COSIGN_PRIVATE_INFRASTRUCTURE=true

$ export IMAGE=<<registry>/test/chains/demo-5:latest@sha256:a6c727554be7f9496e413a789663060cd2e62b3be083954188470a94b66239c7>

$ cosign verify-attestation --key cosign.pub --type cyclonedx $IMAGE | jq -r '.payload | @base64d' | jq -s
```

The output will be similar to the following, which contains the components information of the image.

```json
{
  "_type": "https://in-toto.io/Statement/v0.1",
  "predicateType": "https://cyclonedx.org/bom",
  "predicate": {
    "$schema": "http://cyclonedx.org/schema/bom-1.6.schema.json",
    "bomFormat": "CycloneDX",
    "components": [
      {
        "bom-ref": "os:ubuntu@24.04",
        "licenses": [
          {
            "license": {
              "name": "GPL"
            }
          }
        ],
        "description": "Ubuntu 24.04.2 LTS",
        "name": "ubuntu",
        "type": "operating-system",
        "version": "24.04"
      }
    ],
    "metadata": {
      "timestamp": "2025-06-07T09:56:05Z",
      "tools": {
        "components": [
          {
            "author": "anchore",
            "name": "syft",
            "type": "application",
            "version": "1.23.1"
          }
        ]
      }
    }
  }
}
```

> More details about the cyclonedx SBOM attestation, please refer to [cyclonedx SBOM attestation](https://cyclonedx.org/docs/1.6/json/)

**Description of the fields:**

- `predicateType`: The type of the predicate.
- `predicate`:
  - `components`: The components of the image.
    - `bom-ref`: The BOM reference of the component.
    - `licenses`: The licenses of the component.
      - `license`: The license of the component.
        - `name`: The name of the license.
        - `id`: The id of the license.
    - `name`: The name of the component.
    - `type`: The type of the component.
    - `version`: The version of the component.
  - `metadata`: The metadata of the image.
    - `timestamp`: The timestamp of the image.
    - `tools`:
      - `components`: The components of the tool.
        - `author`: The author of the tool.
        - `name`: The name of the tool.
        - `type`: The type of the tool.
        - `version`: The version of the tool.

### Step 6: Verify the base image information

#### Step 6.1: Create a Kyverno policy to verify the base image information

> This step requires cluster administrator privileges.

The policy is as follows:

```yaml
apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: verify-base-image
spec:
  webhookConfiguration:
    failurePolicy: Fail
    timeoutSeconds: 30
  background: false
  rules:
    - name: check-image
      match:
        any:
          - resources:
              kinds:
                - Pod
              namespaces:
                - policy
      verifyImages:
        - imageReferences:
            - "*"
            # - "<registry>/test/*"
          skipImageReferences:
            - "ghcr.io/trusted/*"
          failureAction: Enforce
          verifyDigest: false
          required: false
          useCache: false
          imageRegistryCredentials:
            allowInsecureRegistry: true
            secrets:
              # The credential needs to exist in the namespace where kyverno is deployed
              - registry-credentials

          attestations:
            - type: https://cyclonedx.org/bom
              attestors:
                - entries:
                    - attestor:
                      keys:
                        publicKeys: |- # <- The public key of the signer
                          -----BEGIN PUBLIC KEY-----
                          MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEFZNGfYwn7+b4uSdEYLKjxWi3xtP3
                          UkR8hQvGrG25r0Ikoq0hI3/tr0m7ecvfM75TKh5jGAlLKSZUJpmCGaTToQ==
                          -----END PUBLIC KEY-----

                        ctlog:
                          ignoreSCT: true

                        rekor:
                          ignoreTlog: true

              conditions:
                - any:
                    - key: "{{ components[?type=='operating-system'] | [?name=='ubuntu' && (version=='22.04' || version=='24.04')] | length(@) }}"
                      operator: GreaterThan
                      value: 0
                      message: "The operating system must be Ubuntu 22.04 or 24.04, not {{ components[?type=='operating-system'].name[] }} {{ components[?type=='operating-system'].version[] }}"

                    - key: "{{ components[?type=='operating-system'] | [?name=='alpine' && (version=='3.18' || version=='3.20')] | length(@) }}"
                      operator: GreaterThan
                      value: 0
                      message: "The operating system must be Alpine 3.18 or 3.20, not {{ components[?type=='operating-system'].name[] }} {{ components[?type=='operating-system'].version[] }}"
```

**Explanation of YAML fields:**

- The policy is largely consistent with the one in [Chapter 1: Create a Kyverno policy to allow only signed images to be deployed](#step-71-create-a-kyverno-policy-to-allow-only-signed-images-to-be-deployed). Below only introduces the differences.
- `spec.rules[0].verifyImages[].attestations[0].conditions`
  - `type`: The cyclonedx SBOM attestation type is `https://cyclonedx.org/bom`
  - `attestors`: the same as above.
  - `conditions`: The conditions to be verified.
    - `any`: Any of the conditions must be met.
      - `key: "{{ components[?type=='operating-system'] | [?name=='ubuntu' && (version=='22.04' || version=='24.04')] | length(@) }}"`: The operating system must be Ubuntu 22.04 or 24.04.
      - `key: "{{ components[?type=='operating-system'] | [?name=='alpine' && (version=='3.18' || version=='3.20')] | length(@) }}"`: The operating system must be Alpine 3.18 or 3.20.

Save the policy to a yaml file named `kyverno.verify-base-image.yaml` and apply it with:

```shell
$ kubectl create -f kyverno.verify-base-image.yaml

clusterpolicy.kyverno.io/verify-base-image created
```

#### Step 6.2: Verify the policy

In the `policy` namespace where the policy is defined, create a Pod to verify the policy.

Use the built image to create a Pod.

```shell
$ export NAMESPACE=<policy>
$ export IMAGE=<<registry>/test/chains/demo-5:latest@sha256:a6c727554be7f9496e413a789663060cd2e62b3be083954188470a94b66239c7>

$ kubectl run -n $NAMESPACE base-image --image=${IMAGE} -- sleep 3600
```

If your base image is Ubuntu 22.04 or 24.04, the Pod will be created successfully.

Change the conditions in the `ClusterPolicy` to only allow Alpine 3.18 or 3.20.

```yaml
conditions:
  - any:
      - key: "{{ components[?type=='operating-system'] | [?name=='alpine' && (version=='3.18' || version=='3.20')] | length(@) }}"
        operator: GreaterThan
        value: 0
        message: "The operating system must be Alpine 3.18 or 3.20, not {{ components[?type=='operating-system'].name[] }} {{ components[?type=='operating-system'].version[] }}"
```

Then create a Pod to verify the policy.

```shell
$ kubectl run -n $NAMESPACE deny-base-image --image=${IMAGE} -- sleep 3600
```

Receive the output like this:

```text
Error from server: admission webhook "mutate.kyverno.svc-fail" denied the request:

resource Pod/policy/deny-base-image was blocked due to the following policies

verify-base-image:
  check-image: 'image attestations verification failed, verifiedCount: 0, requiredCount:
    1, error: .attestations[0].attestors[0].entries[0].keys: attestation checks failed
    for <registry>/test/chains/demo-5:latest and predicate https://cyclonedx.org/bom:
    The operating system must be Alpine 3.18 or 3.20, not ["ubuntu"] ["24.04"]'
```
### Step 7: Clean up the resources

Delete the Pods created in the previous steps.

```shell
$ export NAMESPACE=<policy>
$ kubectl delete pod -n $NAMESPACE base-image
```

Delete the policy.

```shell
$ kubectl delete clusterpolicy verify-base-image
```

## Chapter 6. License Compliance Verification - Rejecting Images with Specific License Types

In ACP (Alauda Container Platform), you can use `trivy` or `syft` task in Tekton Pipeline to generate the SBOM for image.

The SBOM contains license information for each component in the image.
We can use Kyverno policies to reject images that include specific licenses.

Since the SBOM has been generated for the image in [Chapter 5](#chapter-5-base-image-allowlist-verification), we will not create a pipeline here, but directly use the existing image to verify this capability.

> This chapter is based on [Chapter 5](#chapter-5-base-image-allowlist-verification), only adds the logic to validate the license information of the image.

### Step 1: Verify the license information of the image

#### Step 1.1: Create a Kyverno policy to verify the base image information

> This step requires cluster administrator privileges.

The policy is as follows:

```yaml
apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: verify-component-licenses
spec:
  webhookConfiguration:
    failurePolicy: Fail
    timeoutSeconds: 30
  background: false
  rules:
    - name: check-image
      match:
        any:
          - resources:
              kinds:
                - Pod
              namespaces:
                - policy
      verifyImages:
        - imageReferences:
            - "*"
            # - "<registry>/test/*"
          skipImageReferences:
            - "ghcr.io/trusted/*"
          failureAction: Enforce
          verifyDigest: false
          required: false
          useCache: false
          imageRegistryCredentials:
            allowInsecureRegistry: true
            secrets:
              # The credential needs to exist in the namespace where kyverno is deployed
              - registry-credentials

          attestations:
            - type: https://cyclonedx.org/bom
              attestors:
                - entries:
                    - attestor:
                      keys:
                        publicKeys: |- # <- The public key of the signer
                          -----BEGIN PUBLIC KEY-----
                          MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEFZNGfYwn7+b4uSdEYLKjxWi3xtP3
                          UkR8hQvGrG25r0Ikoq0hI3/tr0m7ecvfM75TKh5jGAlLKSZUJpmCGaTToQ==
                          -----END PUBLIC KEY-----

                        ctlog:
                          ignoreSCT: true

                        rekor:
                          ignoreTlog: true

              conditions:
                - any:
                    # Check if the image contains specific licenses
                    - key: "{{ components[].licenses[].license.id }}"
                      operator: AllNotIn
                      value: ["GPL-3.0-only", "GPL-3.0-or-later"]
                      message: |
                        The image contains GPL licenses which are not allowed.
                        Found licenses: {{ components[].licenses[].license.id }}

                    # Check if the image contains specific license names
                    - key: "{{ components[].licenses[].license.name }}"
                      operator: AllNotIn
                      value: ["GPL"]
                      message: |
                        The image contains Expat license which is not allowed.
                        Found licenses: {{ components[].licenses[].license.name }}
```

**Explanation of YAML fields:**

- The policy is largely consistent with the one in [Chapter 1: Create a Kyverno policy to allow only signed images to be deployed](#step-71-create-a-kyverno-policy-to-allow-only-signed-images-to-be-deployed). Below only introduces the differences.
- `spec.rules[0].verifyImages[].attestations[0].conditions`
  - `type`: The cyclonedx SBOM attestation type is `https://cyclonedx.org/bom`
  - `attestors`: the same as above.
  - `conditions`: The conditions to be verified.
    - `any`: Any of the conditions must be met.
      - `key: "{{ components[].licenses[].license.id }}"`: The image contains GPL licenses which are not allowed.
      - `key: "{{ components[].licenses[].license.name }}"`: The image contains Expat license which is not allowed.

Save the policy to a yaml file named `kyverno.verify-component-licenses.yaml` and apply it with:

```shell
$ kubectl create -f kyverno.verify-component-licenses.yaml

clusterpolicy.kyverno.io/verify-component-licenses created
```

#### Step 1.2: Verify the policy

In the `policy` namespace where the policy is defined, create a Pod to verify the policy.

Use the built image to create a Pod.

```shell
$ export NAMESPACE=<policy>
$ export IMAGE=<<registry>/test/chains/demo-5:latest@sha256:a6c727554be7f9496e413a789663060cd2e62b3be083954188470a94b66239c7>

$ kubectl run -n $NAMESPACE component-licenses --image=${IMAGE} -- sleep 3600
```

If your image contains GPL licenses, the Pod will be created failed.

Receive the output like this:

```text
Error from server: admission webhook "mutate.kyverno.svc-fail" denied the request:

resource Pod/policy/high-risk was blocked due to the following policies

verify-component-licenses:
  check-image: |
    image attestations verification failed, verifiedCount: 0, requiredCount: 1, error: .attestations[0].attestors[0].entries[0].keys: attestation checks failed for <registry>/test/chains/demo-5:latest and predicate https://cyclonedx.org/bom: The image contains GPL licenses which are not allowed.
    Found licenses: ["GPL-3.0-only","GPL-3.0-or-later","Latex2e"]
    ; The image contains Expat license which is not allowed.
    Found licenses: [,"GPL","LGPL","public-domain"]
```

Change the license limit in the `ClusterPolicy` to allow GPL licenses.

```yaml
conditions:
  - any:
    - key: "{{ components[].licenses[].license.id }}"
      operator: AllNotIn
      value: ["GPL-8.0-only"]
      message: |
        The image contains GPL licenses which are not allowed.
        Found licenses: {{ components[].licenses[].license.id }}

    - key: "{{ components[].licenses[].license.name }}"
      operator: AllNotIn
      value: ["GPL-x"]
      message: |
        The image contains Expat license which is not allowed.
        Found licenses: {{ components[].licenses[].license.name }}
```

Then create a Pod to verify the policy.

```shell
$ kubectl run -n $NAMESPACE component-licenses --image=${IMAGE} -- sleep 3600

pod/component-licenses created
```

The Pod will be created successfully.

### Step 2: (Optional) Verify Image Check CVE-2022-42889

> **Tips:**:
>
> - If you interested to add more conditions to the policy, you can continue to read the following content.

CVE-2022-42889 is a critical vulnerability in the Apache Commons Text library which could lead to arbitrary code executions and occurs in versions 1.5 through 1.9. Detecting the affected package may be done in an SBOM by identifying the "commons-text" package with one of the affected versions. This policy checks attested SBOMs in CycloneDX format of an image specified under `imageReferences` and denies it if it contains versions 1.5-1.9 of the commons-text package.

We only need to add a condition to the `ClusterPolicy` to check if the `commons-text` package is in the image.

```yaml
conditions:
  - all:
    - key: "{{ components[?name=='commons-text'].version || 'none' }}"
      operator: AllNotIn
      value: ["1.5","1.6","1.7","1.8","1.9"]
```

This is not demonstrated here, interested readers can try it themselves.

### Step 3: Clean up the resources

Delete the Pods created in the previous steps.

```shell
$ export NAMESPACE=<policy>
$ kubectl delete pod -n $NAMESPACE component-licenses
```

Delete the policy.

```shell
$ kubectl delete clusterpolicy verify-component-licenses
```

## Chapter 7. (Optional) Keyless Signing Verification

> **Tips:**:
>
> - If you interested about the keyless signing verification, you can continue to read the following content.
> - The content in this chapter needs to be able to access the public network.
> - But you can use the private Rekor services if you have already deployed them.

While ACP (Alauda Container Platform) currently does not provide the capability to deploy private Rekor instances, it does offer integration capabilities with Rekor services.

Here, we take the integration of public Rekor as an example to introduce how to use these services.
If you have already deployed private Rekor services, please refer to the relevant documentation for configuration.

### Step 1: Prerequisites

Please check if the prerequisites are completed, especially about this section:

- [Registry Configuration](#registry-configuration)
- [ServiceAccount Configuration](#serviceaccount-configuration)
- [Get the signing public key](#get-the-signing-public-key)
- [rekor-cli](https://github.com/sigstore/rekor/releases)
  - Used to verify and interact with attestations stored in the Rekor transparency log server.
- [jq](https://stedolan.github.io/jq/)
  - To present the contents of the signature in a friendly manner.

### Step 2: Configure the Tekton Chains

> This process requires platform administrator privileges to configure.

Configure the transparency log of Tekton Chains

```shell
$ kubectl patch tektonconfigs.operator.tekton.dev config --type=merge -p='{
  "spec": {
    "chain": {
      "transparency.enabled": true
    }
  }
}'
```

> If you have private Rekor services, you can set the `transparency.url` to the URL of your Rekor server.
> - `transparency.url: "<https://rekor.sigstore.dev>"`

> More details about the configuration, please refer to [Transparency Log](https://tekton.dev/docs/chains/config/#transparency-log)

### Step 3: Re-run the pipeline to generate the image

> **Tips:**:
>
> - Since we modified the transparency log configuration, we need to trigger a new pipeline run in [Chapter 1](#step-3-run-the-pipeline-to-generate-the-image).
> - This will allow Tekton Chains to generate transparency log entries for new image and PipelineRun.

To regenerate and obtain the image, follow these steps:

- [Chapter 1: Run the pipeline to generate the image](#step-3-run-the-pipeline-to-generate-the-image)
- [Chapter 1: Wait for the pipeline to be signed](#step-4-wait-for-the-pipeline-to-be-signed)

### Step 4: Get the rekor log index

Get the rekor signature from the annotations of the PipelineRun.

```shell
$ export NAMESPACE=<pipeline-namespace>
$ export PIPELINERUN_NAME=<pipelinerun-name>
$ kubectl get pipelinerun -n $NAMESPACE $PIPELINERUN_NAME -o jsonpath='{.metadata.annotations.chains\.tekton\.dev/transparency}'

https://rekor.sigstore.dev/api/v1/log/entries?logIndex=232330257
```

### Step 5: Get the rekor signature by curl

```shell
$ curl -s "https://rekor.sigstore.dev/api/v1/log/entries?logIndex=232330257" | jq
```

If you need to view the content of the rekor signature, you can execute the following command:

```shell
$ curl -s "https://rekor.sigstore.dev/api/v1/log/entries?logIndex=232330257" | jq -r '.[keys[0]].attestation.data | @base64d' | jq .

{
  "_type": "https://in-toto.io/Statement/v0.1",
  "subject": null,
  "predicateType": "https://slsa.dev/provenance/v0.2",
  "predicate": {
    "buildType": "tekton.dev/v1beta1/PipelineRun",
    "builder": {
      "id": "https://alauda.io/builders/tekton/v1"
    },
    "materials": [
      {
        "digest": {
          "sha256": "8d5ea9ecd9b531e798fecd87ca3b64ee1c95e4f2621d09e893c58ed593bfd4c4"
        },
        "uri": "oci://<registry>/devops/tektoncd/hub/buildah"
      }
    ],
    "metadata": {
      "buildFinishedOn": "2025-06-08T03:11:52Z",
      "buildStartedOn": "2025-06-08T03:10:33Z"
    }
  }
}
```

This content is same as the attestation in the image, which verifies the authenticity and integrity of the image content.
The attestation information can be retrieved from Rekor without requiring credentials from the image registry, making it more convenient and accessible for verification purposes.

### Step 6: Get the rekor signature by rekor-cli

Get signature by log index

```shell
# the log index is same as the one in the annotations of the PipelineRun
$ rekor-cli get --log-index 232330257 --format json | jq -r .Attestation | jq .
```

Get signature by image digest

```shell
# get the uuid by image digest
$ rekor-cli search --sha da4885861a8304abad71fcdd569c92daf33422073d1102013a1fed615dfb285a

Found matching entries (listed by UUID):
108e9186e8c5677a1364e68001a916d3a7316bc2580bd6b5fbbce39a9c62f13282d3e974a6b434ab

# get the signature by uuid
$ rekor-cli get --uuid 108e9186e8c5677a1364e68001a916d3a7316bc2580bd6b5fbbce39a9c62f13282d3e974a6b434ab --format json | jq -r .Attestation | jq .
```

### Step 7: Verify the rekor in Kyverno

Modify the `keys` section of the `ClusterPolicy` to add rekor verification.

```yaml

apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
spec:
  rules:
    - name: check-image
      verifyImages:
        - attestors:
            - count: 1
              entries:
                - keys:
                    publicKeys: |- # <- The public key of the signer
                      -----BEGIN PUBLIC KEY-----
                      MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEFZNGfYwn7+b4uSdEYLKjxWi3xtP3
                      UkR8hQvGrG25r0Ikoq0hI3/tr0m7ecvfM75TKh5jGAlLKSZUJpmCGaTToQ==
                      -----END PUBLIC KEY-----

                    rekor:
                      ignoreTlog: false
                      # url: <https://rekor.sigstore.dev>
                      # # get the public key from the rekor server
                      # # curl <https://rekor.sigstore.dev>/api/v1/log/publicKey
                      # pubkey: |-
                      #   -----BEGIN PUBLIC KEY-----
                      #   MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAE2G2Y+2tabdTV5BcGiBIx0a9fAFwr
                      #   kBbmLSGtks4L3qX6yYY0zufBnhC8Ur/iy55GhWP/9A/bY2LhC30M9+RYtw==
                      #   -----END PUBLIC KEY-----
```

**Explanation of YAML fields:**
- `rekor`: The rekor verification configuration.
  - `ignoreTlog`: Whether to ignore the transparency log.
    - If `false`, the rekor server will be verified.
  - `url`: The URL of the rekor server.
    - If not set, the default rekor server `https://rekor.sigstore.dev` will be used.
  - `pubkey`: The public key of the signer.
    - If not set, the public key will be fetched from the rekor server.
    - If the rekor server is private, you need to get the public key from the rekor server.
      - `curl <https://rekor.sigstore.dev>/api/v1/log/publicKey`

If your image not signed, the Pod will be blocked.

```text
Error from server: admission webhook "mutate.kyverno.svc-fail" denied the request:

resource Pod/policy/sign was blocked due to the following policies

only-cosign-image-deploy:
  check-image: 'failed to verify image <registry>/test/chains/demo-1:latest:
    .attestors[0].entries[0].keys: no matching signatures: searching log query: Post
    "http:///api/v1/log/entries/retrieve": POST http:///api/v1/log/entries/retrieve
    giving up after 4 attempt(s): Post "http:///api/v1/log/entries/retrieve": http:
    no Host in request URL'
```

## Conclusion

Alauda Container Platform (ACP) provides a comprehensive solution for implementing software supply chain security through the OpenSSF SLSA framework. This document has explored the key components and implementation methods that enable secure and reliable software delivery:

### Core Security Capabilities

1. **Code and Build Process Security**
   - Code repository from trusted git sources
   - SLSA Provenance for build process attestation
   - Image integrity through signing and verification
   - Modern keyless signing solutions
   - Build environment verification and hardening

2. **Dependency and Component Security**
   - Vulnerability scanning for security risk assessment
   - Component inventory via SBOM generation
   - License compliance verification
   - Third-party dependency validation

3. **Distribution and Deployment Security**
   - Policy-based validation using Kyverno
   - Flexible validation mechanisms
   - Automated security policy enforcement
   - Runtime environment security controls

### Implementation Architecture

1. **Core Components**
   - Tekton Pipelines: For pipeline orchestration and automation
   - Tekton Chains: For SLSA compliance and artifact signing
   - Kyverno: For policy enforcement and validation

2. **Supporting Tools**
   - cosign: For image signing and verification
   - syft/trivy: For SBOM generation and vulnerability scanning
   - trivy/grype: For vulnerability scanning

3. **Implementation Process**
   - Phase 1: Attestation Generation
   - Phase 2: Attestation Validation

### Key Benefits

1. **Comprehensive Risk Mitigation**
   - Ensures build process integrity and traceability
   - Provides comprehensive vulnerability management
   - Supports modern signing methods without key management overhead
   - Addresses all major supply chain security risks

2. **Operational Efficiency**
   - Enables automated security policy enforcement
   - Reduces manual security checks
   - Streamlines compliance verification
   - Simplifies security management

3. **Implementation Flexibility**
   - Multiple tools for each security feature
   - Customizable validation rules
   - Integration with existing CI/CD pipelines
   - Adaptable to different security requirements

By implementing these supply chain security measures, organizations can significantly improve their software delivery process, reduce security risks, and ensure compliance with industry standards. The platform's flexibility allows teams to choose the most appropriate security controls based on their specific requirements, while maintaining a robust and reliable software supply chain.

## References

- [SLSA](https://slsa.dev/)
  - [Supply chain threats](https://slsa.dev/spec/v1.1/threats-overview)
  - [Security levels](https://slsa.dev/spec/v1.1/levels)
- [Tekton Chains](https://tekton.dev/docs/chains/)
  - [Chains Configuration](https://tekton.dev/docs/chains/config/)
  - [SLSA Provenance](https://tekton.dev/docs/chains/slsa-provenance/)
  - [Getting To SLSA Level 2 with Tekton and Tekton Chains](https://tekton.dev/blog/2023/04/19/getting-to-slsa-level-2-with-tekton-and-tekton-chains/)
- [Cosign](https://github.com/sigstore/cosign)
  - [Cosign Signature Specifications](https://github.com/sigstore/cosign/blob/main/specs/SIGNATURE_SPEC.md)
  - [Cosign Vulnerability Scan Record Attestation Specification](https://github.com/sigstore/cosign/blob/main/specs/COSIGN_VULN_ATTESTATION_SPEC.md)
  - [Validate In-Toto Attestations](https://docs.sigstore.dev/cosign/verifying/attestation/)
- [Kyverno](https://kyverno.io/)
  - [ClusterPolicy Specification](https://htmlpreview.github.io/?https://github.com/kyverno/kyverno/blob/main/docs/user/crd/index.html)
  - [Kyverno - JMESPath](https://release-1-11-0.kyverno.io/docs/writing-policies/jmespath/)
  - kyverno provides a series of [policies](https://kyverno.io/policies/?policytypes=Security+Tekton+Tekton%2520in%2520CEL+verifyImages)
    - [Check Tekton TaskRun Vulnerability Scan](https://kyverno.io/policies/tekton/verify-tekton-taskrun-vuln-scan/verify-tekton-taskrun-vuln-scan/): Check for high-risk vulnerabilities
    - [Require Signed Tekton Task](https://kyverno.io/policies/tekton/verify-tekton-taskrun-signatures/verify-tekton-taskrun-signatures/): Require signature information for the bundle in Tekton TaskRun's TaskRef
    - [Require Image Vulnerability Scans](https://kyverno.io/policies/other/require-vulnerability-scan/require-vulnerability-scan/): Require vulnerability scan information within 168h for images
    - [Verify Image Check CVE-2022-42889](https://kyverno.io/policies/other/verify-image-cve-2022-42889/verify-image-cve-2022-42889/): Require images to be free of CVE-2022-42889 vulnerability
